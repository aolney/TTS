{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# South Park TTS Training\n",
    "\n",
    "Adapted [this gist](https://gist.github.com/erogol/97516ad65b44dbddb8cd694953187c5b) for [SoS notebook](https://vatlab.github.io/sos-docs/).\n",
    "\n",
    "Assumes you have already [cloned TTS](https://github.com/mozilla/TTS) and done `apt install espeak`\n",
    "\n",
    "## Prepare Training/Testing Data\n",
    "\n",
    "Assumes you have already [prepared suitable data](https://github.com/aolney/SouthParkTTSData).\n",
    "The next step simply does a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18515 metadata.csv\n"
     ]
    }
   ],
   "source": [
    "cd /y/south-park-1-to-20\n",
    "echo `wc -l metadata.csv`\n",
    "shuf metadata.csv > metadata_shuf.csv\n",
    "head -n 18000 metadata_shuf.csv > metadata_train.csv\n",
    "tail -n 515 metadata_shuf.csv > metadata_val.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Create config file for this training data\n",
    "\n",
    "Some of my local paths are hardcoded below. Parameters determined using [wiki documentation](https://github.com/mozilla/TTS/wiki/Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "#exit #comment to allow execution\n",
    "cd /vm/TTS\n",
    "cp config.json \"config.json.$(date +%Y%m%d)\"\n",
    "cat > config.json << EOM\n",
    "{\n",
    "    \"model_name\": \"queue\",\n",
    "    \"model_description\": \"Queue memory and change lower r incrementatlly\",\n",
    "\n",
    "    \"audio\":{\n",
    "        // Audio processing parameters\n",
    "        \"num_mels\": 80,         // size of the mel spec frame. \n",
    "        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\n",
    "        \"sample_rate\": 16000,   // wav sample-rate. If different than the original data, it is resampled.\n",
    "        \"frame_length_ms\": 50,  // stft window length in ms.\n",
    "        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\n",
    "        \"preemphasis\": 0.99,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\n",
    "        \"min_level_db\": -100,   // normalization range\n",
    "        \"ref_level_db\": 40,     // reference level db, theoretically 20db is the sound of air.\n",
    "        \"power\": 1.1,           // value to sharpen wav signals after GL algorithm.\n",
    "        \"griffin_lim_iters\": 30,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\n",
    "        // Normalization parameters\n",
    "        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\n",
    "        \"symmetric_norm\": false, // move normalization to range [-1, 1]\n",
    "        \"max_norm\": 1,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\n",
    "        \"clip_norm\": true,      // clip normalized values into the range.\n",
    "        \"mel_fmin\": null,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\n",
    "        \"mel_fmax\": null,        // maximum freq level for mel-spec. Tune for dataset!!\n",
    "        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\n",
    "    },\n",
    "\n",
    "    \"distributed\":{\n",
    "        \"backend\": \"nccl\",\n",
    "        \"url\": \"tcp:\\/\\/localhost:54321\"\n",
    "    },\n",
    "\n",
    "    \"embedding_size\": 256,  // Character embedding vector length. You don't need to change it in general.\n",
    "    \"text_cleaner\": \"phoneme_cleaners\",\n",
    "    \"epochs\": 1000,         // total number of epochs to train (originally 1000)\n",
    "    \"lr\": 0.0001,            // Initial learning rate. If Noam decay is active, maximum learning rate.\n",
    "    \"lr_decay\": false,      // if true, Noam learning rate decaying is applied through training.\n",
    "    \"loss_weight\": 0.0,     // loss weight to emphasize lower frequencies. Lower frequencies are in general more important for speech signals.\n",
    "    \"warmup_steps\": 4000,   // Noam decay steps to increase the learning rate from 0 to \"lr\"\n",
    "    \"windowing\": false,      // Enables attention windowing. Used only in eval mode.\n",
    "    \"memory_size\": 5,       // memory queue size used to queue network predictions to feed autoregressive connection. Useful if r < 5. \n",
    "\n",
    "    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention.\n",
    "    \"eval_batch_size\":32,   \n",
    "    \"r\": 5,                 // Number of frames to predict for step.\n",
    "    \"wd\": 0.00001,          // Weight decay weight.\n",
    "    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\n",
    "    \"save_step\": 5000,      // Number of training steps expected to save traning stats and checkpoints.\n",
    "    \"print_step\": 50,       // Number of steps to log traning on console.\n",
    "    \"tb_model_param_stats\": false,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging. \n",
    "    \"batch_group_size\": 8,  //Number of batches to shuffle after bucketing.\n",
    "\n",
    "    \"test_delay_epochs\":1,\n",
    "    \"run_eval\": true,\n",
    "    \"data_path\": \"/y/south-park-1-to-20/\",  // can overwritten from command argument\n",
    "    \"meta_file_train\": \"metadata_train.csv\",      // metafile for training dataloader\n",
    "    \"meta_file_val\": \"metadata_val.csv\",    // metafile for validation dataloader\n",
    "    \"data_loader\": \"TTSDataset\",      // dataloader, [\"TTSDataset\", \"TTSDatasetCached\", \"TTSDatasetMemory\"]\n",
    "    \"dataset\": \"ljspeech\",     // one of TTS.dataset.preprocessors, only valid id dataloader == \"TTSDataset\", rest uses \"tts_cache\" by default.\n",
    "    \"min_seq_len\": 0,       // DATASET-RELATED: minimum text length to use in training\n",
    "    \"max_seq_len\": 300,     // DATASET-RELATED: maximum text length\n",
    "    \"output_path\": \"/vm/TTS/models/cartman_models/\",\n",
    "    \"num_loader_workers\": 2,\n",
    "    \"num_val_loader_workers\": 2,\n",
    "     \"phoneme_cache_path\": \"cartman_phonemes\",  // phoneme computation is slow, therefore, it caches results in the given folder.\n",
    "    \"use_phonemes\": true,           // use phonemes instead of raw characters. It is suggested for better pronounciation.\n",
    "    \"phoneme_language\": \"en-us\",     // depending on your target language, pick one from  https://github.com/bootphon/phonemizer#languages\n",
    "    \"text_cleaner\": \"phoneme_cleaners\"\n",
    "}\n",
    "EOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using CUDA:  True\n",
      " > Number of GPUs:  2\n",
      " > Forcing use of single GPU, id:  GeForce GTX 1080 Ti\n",
      " > Git Hash: 59bbdb3\n",
      " > Experiment folder: /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3\n",
      " > Setting up Audio Processor...\n",
      " | > bits:None\n",
      " | > sample_rate:16000\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:12.5\n",
      " | > frame_length_ms:50\n",
      " | > ref_level_db:40\n",
      " | > num_freq:1025\n",
      " | > power:1.1\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:30\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > n_fft:2048\n",
      " | > hop_length:200\n",
      " | > win_length:800\n",
      "\n",
      " > Model has 7079698 parameters\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Data path: /y/south-park-1-to-20/\n",
      " | > Use phonemes: True\n",
      "   | > phoneme language: en-us\n",
      " | > Cached dataset: False\n",
      " | > Number of instances : 18000\n",
      " | > Max length sequence: 62\n",
      " | > Min length sequence: 1\n",
      " | > Avg length sequence: 30.831222222222223\n",
      " | > Num. instances discarded by max-min seq limits: 0\n",
      " | > Batch group size: 256.\n",
      "\n",
      " > Epoch 0/1000\n",
      " | > Step:49/562  GlobalStep:50  TotalLoss:0.29713  LinearLoss:0.17064  MelLoss:0.12649  StopLoss:0.74109  GradNorm:0.11746  GradNormST:2.04799  AvgTextLen:14.3  AvgSpecLen:89.2  StepTime:0.31  LR:0.000100\n",
      " | > Step:99/562  GlobalStep:100  TotalLoss:0.20432  LinearLoss:0.09732  MelLoss:0.10700  StopLoss:0.69300  GradNorm:0.11667  GradNormST:1.01413  AvgTextLen:18.6  AvgSpecLen:90.5  StepTime:0.33  LR:0.000100\n",
      " | > Step:149/562  GlobalStep:150  TotalLoss:0.19668  LinearLoss:0.09049  MelLoss:0.10619  StopLoss:0.69561  GradNorm:0.15205  GradNormST:2.51883  AvgTextLen:22.1  AvgSpecLen:121.8  StepTime:0.35  LR:0.000100\n",
      " | > Step:199/562  GlobalStep:200  TotalLoss:0.18696  LinearLoss:0.08735  MelLoss:0.09961  StopLoss:0.65629  GradNorm:0.20035  GradNormST:0.91564  AvgTextLen:26.6  AvgSpecLen:116.8  StepTime:0.40  LR:0.000100\n",
      " | > Step:249/562  GlobalStep:250  TotalLoss:0.19220  LinearLoss:0.08965  MelLoss:0.10255  StopLoss:0.62697  GradNorm:0.10209  GradNormST:2.52390  AvgTextLen:29.1  AvgSpecLen:125.1  StepTime:0.35  LR:0.000100\n",
      " | > Step:299/562  GlobalStep:300  TotalLoss:0.18054  LinearLoss:0.08393  MelLoss:0.09661  StopLoss:0.51531  GradNorm:0.06654  GradNormST:1.97493  AvgTextLen:33.2  AvgSpecLen:143.1  StepTime:0.58  LR:0.000100\n",
      " | > Step:349/562  GlobalStep:350  TotalLoss:0.17609  LinearLoss:0.08525  MelLoss:0.09083  StopLoss:0.38164  GradNorm:0.05029  GradNormST:1.20173  AvgTextLen:35.9  AvgSpecLen:127.4  StepTime:0.46  LR:0.000100\n",
      " | > Step:399/562  GlobalStep:400  TotalLoss:0.17488  LinearLoss:0.08553  MelLoss:0.08935  StopLoss:0.40130  GradNorm:0.10271  GradNormST:0.99698  AvgTextLen:40.1  AvgSpecLen:137.2  StepTime:0.38  LR:0.000100\n",
      " | > Step:449/562  GlobalStep:450  TotalLoss:0.17287  LinearLoss:0.08450  MelLoss:0.08837  StopLoss:0.36127  GradNorm:0.07160  GradNormST:0.72854  AvgTextLen:43.5  AvgSpecLen:140.0  StepTime:0.35  LR:0.000100\n",
      " | > Step:499/562  GlobalStep:500  TotalLoss:0.16868  LinearLoss:0.08418  MelLoss:0.08450  StopLoss:0.30876  GradNorm:0.04062  GradNormST:0.87703  AvgTextLen:50.0  AvgSpecLen:159.9  StepTime:0.39  LR:0.000100\n",
      " | > Step:549/562  GlobalStep:550  TotalLoss:0.17016  LinearLoss:0.08551  MelLoss:0.08465  StopLoss:0.27737  GradNorm:0.04382  GradNormST:0.46161  AvgTextLen:57.5  AvgSpecLen:196.3  StepTime:0.53  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:563  AvgTotalLoss:0.74918  AvgLinearLoss:0.10378  AvgMelLoss:0.10771  AvgStopLoss:0.53769  EpochTime:246.95  AvgStepTime:0.44\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.57999   LinearLoss: 0.08653   MelLoss:0.08002  StopLoss: 0.41344  \n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.10378   Validation Loss: 0.09089\n",
      "\n",
      " > BEST MODEL (0.09089) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 1/1000\n",
      " | > Step:36/562  GlobalStep:600  TotalLoss:0.15735  LinearLoss:0.08232  MelLoss:0.07503  StopLoss:0.32333  GradNorm:0.07668  GradNormST:1.47812  AvgTextLen:11.1  AvgSpecLen:94.9  StepTime:0.40  LR:0.000100\n",
      " | > Step:86/562  GlobalStep:650  TotalLoss:0.15658  LinearLoss:0.08143  MelLoss:0.07515  StopLoss:0.34566  GradNorm:0.08949  GradNormST:0.84651  AvgTextLen:17.8  AvgSpecLen:101.8  StepTime:0.28  LR:0.000100\n",
      " | > Step:136/562  GlobalStep:700  TotalLoss:0.15549  LinearLoss:0.08041  MelLoss:0.07509  StopLoss:0.22419  GradNorm:0.03491  GradNormST:1.65473  AvgTextLen:21.2  AvgSpecLen:101.7  StepTime:0.58  LR:0.000100\n",
      " | > Step:186/562  GlobalStep:750  TotalLoss:0.15890  LinearLoss:0.08197  MelLoss:0.07693  StopLoss:0.30781  GradNorm:0.04534  GradNormST:0.91342  AvgTextLen:25.1  AvgSpecLen:105.1  StepTime:0.30  LR:0.000100\n",
      " | > Step:236/562  GlobalStep:800  TotalLoss:0.16613  LinearLoss:0.08555  MelLoss:0.08058  StopLoss:0.29526  GradNorm:0.08713  GradNormST:0.47057  AvgTextLen:28.4  AvgSpecLen:100.3  StepTime:0.46  LR:0.000100\n",
      " | > Step:286/562  GlobalStep:850  TotalLoss:0.16743  LinearLoss:0.08437  MelLoss:0.08306  StopLoss:0.23407  GradNorm:0.09805  GradNormST:0.39744  AvgTextLen:31.7  AvgSpecLen:124.8  StepTime:0.55  LR:0.000100\n",
      " | > Step:336/562  GlobalStep:900  TotalLoss:0.16249  LinearLoss:0.08368  MelLoss:0.07881  StopLoss:0.28312  GradNorm:0.09758  GradNormST:0.81547  AvgTextLen:36.0  AvgSpecLen:125.1  StepTime:0.40  LR:0.000100\n",
      " | > Step:386/562  GlobalStep:950  TotalLoss:0.15395  LinearLoss:0.07896  MelLoss:0.07499  StopLoss:0.26468  GradNorm:0.06576  GradNormST:0.68138  AvgTextLen:39.4  AvgSpecLen:154.3  StepTime:0.53  LR:0.000100\n",
      " | > Step:436/562  GlobalStep:1000  TotalLoss:0.15647  LinearLoss:0.08007  MelLoss:0.07641  StopLoss:0.23544  GradNorm:0.05375  GradNormST:0.78394  AvgTextLen:42.3  AvgSpecLen:160.9  StepTime:0.53  LR:0.000100\n",
      " | > Step:486/562  GlobalStep:1050  TotalLoss:0.15735  LinearLoss:0.08063  MelLoss:0.07672  StopLoss:0.24930  GradNorm:0.08284  GradNormST:1.19513  AvgTextLen:49.7  AvgSpecLen:186.6  StepTime:0.64  LR:0.000100\n",
      " | > Step:536/562  GlobalStep:1100  TotalLoss:0.16033  LinearLoss:0.08227  MelLoss:0.07806  StopLoss:0.18290  GradNorm:0.13547  GradNormST:0.22189  AvgTextLen:55.9  AvgSpecLen:186.5  StepTime:0.57  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:1126  AvgTotalLoss:0.43456  AvgLinearLoss:0.08152  AvgMelLoss:0.07657  AvgStopLoss:0.27647  EpochTime:288.26  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.58030   LinearLoss: 0.08196   MelLoss:0.06466  StopLoss: 0.43368  \n",
      " | > Training Loss: 0.08152   Validation Loss: 0.08758\n",
      "\n",
      " > BEST MODEL (0.08758) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 2/1000\n",
      " | > Step:23/562  GlobalStep:1150  TotalLoss:0.13364  LinearLoss:0.07320  MelLoss:0.06044  StopLoss:0.32961  GradNorm:0.11569  GradNormST:1.29897  AvgTextLen:8.1  AvgSpecLen:97.9  StepTime:0.38  LR:0.000100\n",
      " | > Step:73/562  GlobalStep:1200  TotalLoss:0.14805  LinearLoss:0.07837  MelLoss:0.06968  StopLoss:0.24870  GradNorm:0.15988  GradNormST:2.54116  AvgTextLen:16.7  AvgSpecLen:108.7  StepTime:0.52  LR:0.000100\n",
      " | > Step:123/562  GlobalStep:1250  TotalLoss:0.14299  LinearLoss:0.07431  MelLoss:0.06869  StopLoss:0.27661  GradNorm:0.05488  GradNormST:0.41689  AvgTextLen:20.5  AvgSpecLen:105.1  StepTime:0.44  LR:0.000100\n",
      " | > Step:173/562  GlobalStep:1300  TotalLoss:0.14813  LinearLoss:0.07553  MelLoss:0.07261  StopLoss:0.22536  GradNorm:0.05711  GradNormST:0.49706  AvgTextLen:25.2  AvgSpecLen:120.4  StepTime:0.57  LR:0.000100\n",
      " | > Step:223/562  GlobalStep:1350  TotalLoss:0.14589  LinearLoss:0.07506  MelLoss:0.07083  StopLoss:0.29797  GradNorm:0.04528  GradNormST:0.51339  AvgTextLen:27.6  AvgSpecLen:118.1  StepTime:0.44  LR:0.000100\n",
      " | > Step:273/562  GlobalStep:1400  TotalLoss:0.14750  LinearLoss:0.07521  MelLoss:0.07229  StopLoss:0.31695  GradNorm:0.05478  GradNormST:0.91615  AvgTextLen:31.3  AvgSpecLen:118.9  StepTime:0.42  LR:0.000100\n",
      " | > Step:323/562  GlobalStep:1450  TotalLoss:0.15100  LinearLoss:0.07704  MelLoss:0.07396  StopLoss:0.26904  GradNorm:0.09139  GradNormST:0.61466  AvgTextLen:34.7  AvgSpecLen:124.1  StepTime:0.44  LR:0.000100\n",
      " | > Step:373/562  GlobalStep:1500  TotalLoss:0.14594  LinearLoss:0.07516  MelLoss:0.07079  StopLoss:0.24471  GradNorm:0.03715  GradNormST:0.56603  AvgTextLen:38.2  AvgSpecLen:143.6  StepTime:0.48  LR:0.000100\n",
      " | > Step:423/562  GlobalStep:1550  TotalLoss:0.15376  LinearLoss:0.07813  MelLoss:0.07563  StopLoss:0.22428  GradNorm:0.07828  GradNormST:0.11675  AvgTextLen:41.3  AvgSpecLen:124.3  StepTime:0.46  LR:0.000100\n",
      " | > Step:473/562  GlobalStep:1600  TotalLoss:0.14599  LinearLoss:0.07745  MelLoss:0.06855  StopLoss:0.16856  GradNorm:0.14856  GradNormST:0.29120  AvgTextLen:46.7  AvgSpecLen:194.6  StepTime:0.94  LR:0.000100\n",
      " | > Step:523/562  GlobalStep:1650  TotalLoss:0.15617  LinearLoss:0.07838  MelLoss:0.07779  StopLoss:0.22872  GradNorm:0.05988  GradNormST:0.81806  AvgTextLen:52.8  AvgSpecLen:167.5  StepTime:0.38  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:1689  AvgTotalLoss:0.40580  AvgLinearLoss:0.07650  AvgMelLoss:0.07280  AvgStopLoss:0.25650  EpochTime:283.79  AvgStepTime:0.50\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.54530   LinearLoss: 0.07416   MelLoss:0.06042  StopLoss: 0.41073  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.07650   Validation Loss: 0.07882\n",
      "\n",
      " > BEST MODEL (0.07882) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 3/1000\n",
      " | > Step:10/562  GlobalStep:1700  TotalLoss:0.12265  LinearLoss:0.06932  MelLoss:0.05333  StopLoss:0.41917  GradNorm:0.12240  GradNormST:3.50787  AvgTextLen:6.8  AvgSpecLen:90.1  StepTime:0.51  LR:0.000100\n",
      " | > Step:60/562  GlobalStep:1750  TotalLoss:0.13505  LinearLoss:0.07100  MelLoss:0.06405  StopLoss:0.29308  GradNorm:0.12973  GradNormST:0.65653  AvgTextLen:14.9  AvgSpecLen:91.5  StepTime:0.48  LR:0.000100\n",
      " | > Step:110/562  GlobalStep:1800  TotalLoss:0.14157  LinearLoss:0.07222  MelLoss:0.06935  StopLoss:0.20630  GradNorm:0.08774  GradNormST:1.92552  AvgTextLen:19.0  AvgSpecLen:95.6  StepTime:0.61  LR:0.000100\n",
      " | > Step:160/562  GlobalStep:1850  TotalLoss:0.14319  LinearLoss:0.07297  MelLoss:0.07022  StopLoss:0.28217  GradNorm:0.08366  GradNormST:0.88903  AvgTextLen:23.5  AvgSpecLen:100.1  StepTime:0.32  LR:0.000100\n",
      " | > Step:210/562  GlobalStep:1900  TotalLoss:0.14233  LinearLoss:0.07144  MelLoss:0.07089  StopLoss:0.22570  GradNorm:0.06659  GradNormST:0.57074  AvgTextLen:27.3  AvgSpecLen:118.0  StepTime:0.51  LR:0.000100\n",
      " | > Step:260/562  GlobalStep:1950  TotalLoss:0.14952  LinearLoss:0.07571  MelLoss:0.07381  StopLoss:0.17407  GradNorm:0.04965  GradNormST:1.18010  AvgTextLen:30.3  AvgSpecLen:126.4  StepTime:0.44  LR:0.000100\n",
      " | > Step:310/562  GlobalStep:2000  TotalLoss:0.14629  LinearLoss:0.07470  MelLoss:0.07159  StopLoss:0.23266  GradNorm:0.06541  GradNormST:0.39377  AvgTextLen:33.6  AvgSpecLen:139.1  StepTime:0.59  LR:0.000100\n",
      " | > Step:360/562  GlobalStep:2050  TotalLoss:0.14508  LinearLoss:0.07373  MelLoss:0.07135  StopLoss:0.23248  GradNorm:0.03953  GradNormST:0.79059  AvgTextLen:37.2  AvgSpecLen:148.1  StepTime:0.55  LR:0.000100\n",
      " | > Step:410/562  GlobalStep:2100  TotalLoss:0.15098  LinearLoss:0.07575  MelLoss:0.07523  StopLoss:0.14867  GradNorm:0.07070  GradNormST:1.24648  AvgTextLen:40.7  AvgSpecLen:138.0  StepTime:0.78  LR:0.000100\n",
      " | > Step:460/562  GlobalStep:2150  TotalLoss:0.14602  LinearLoss:0.07421  MelLoss:0.07181  StopLoss:0.21379  GradNorm:0.05539  GradNormST:0.76668  AvgTextLen:45.4  AvgSpecLen:164.7  StepTime:0.45  LR:0.000100\n",
      " | > Step:510/562  GlobalStep:2200  TotalLoss:0.14600  LinearLoss:0.07325  MelLoss:0.07274  StopLoss:0.17075  GradNorm:0.03663  GradNormST:0.13057  AvgTextLen:50.8  AvgSpecLen:171.5  StepTime:0.74  LR:0.000100\n",
      " | > Step:560/562  GlobalStep:2250  TotalLoss:0.14898  LinearLoss:0.07561  MelLoss:0.07337  StopLoss:0.16650  GradNorm:0.06270  GradNormST:0.17028  AvgTextLen:61.9  AvgSpecLen:193.4  StepTime:0.42  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:2252  AvgTotalLoss:0.38119  AvgLinearLoss:0.07377  AvgMelLoss:0.07044  AvgStopLoss:0.23698  EpochTime:290.49  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.55908   LinearLoss: 0.07192   MelLoss:0.05934  StopLoss: 0.42782  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.07377   Validation Loss: 0.07742\n",
      "\n",
      " > BEST MODEL (0.07742) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 4/1000\n",
      " | > Step:47/562  GlobalStep:2300  TotalLoss:0.13611  LinearLoss:0.07127  MelLoss:0.06484  StopLoss:0.25049  GradNorm:0.07610  GradNormST:0.77233  AvgTextLen:11.8  AvgSpecLen:95.0  StepTime:0.45  LR:0.000100\n",
      " | > Step:97/562  GlobalStep:2350  TotalLoss:0.14205  LinearLoss:0.07183  MelLoss:0.07022  StopLoss:0.27436  GradNorm:0.09051  GradNormST:0.48091  AvgTextLen:18.2  AvgSpecLen:94.2  StepTime:0.30  LR:0.000100\n",
      " | > Step:147/562  GlobalStep:2400  TotalLoss:0.14961  LinearLoss:0.07573  MelLoss:0.07388  StopLoss:0.23039  GradNorm:0.11825  GradNormST:0.26599  AvgTextLen:22.6  AvgSpecLen:95.4  StepTime:0.44  LR:0.000100\n",
      " | > Step:197/562  GlobalStep:2450  TotalLoss:0.14633  LinearLoss:0.07379  MelLoss:0.07254  StopLoss:0.22128  GradNorm:0.05939  GradNormST:0.18316  AvgTextLen:26.3  AvgSpecLen:107.7  StepTime:0.33  LR:0.000100\n",
      " | > Step:247/562  GlobalStep:2500  TotalLoss:0.14001  LinearLoss:0.07141  MelLoss:0.06860  StopLoss:0.25573  GradNorm:0.04512  GradNormST:0.20801  AvgTextLen:29.6  AvgSpecLen:123.5  StepTime:0.44  LR:0.000100\n",
      " | > Step:297/562  GlobalStep:2550  TotalLoss:0.14092  LinearLoss:0.07156  MelLoss:0.06935  StopLoss:0.17836  GradNorm:0.08905  GradNormST:0.20611  AvgTextLen:32.8  AvgSpecLen:140.8  StepTime:0.65  LR:0.000100\n",
      " | > Step:347/562  GlobalStep:2600  TotalLoss:0.15276  LinearLoss:0.07643  MelLoss:0.07633  StopLoss:0.21190  GradNorm:0.07208  GradNormST:0.19066  AvgTextLen:35.2  AvgSpecLen:128.2  StepTime:0.48  LR:0.000100\n",
      " | > Step:397/562  GlobalStep:2650  TotalLoss:0.14532  LinearLoss:0.07282  MelLoss:0.07250  StopLoss:0.20181  GradNorm:0.03737  GradNormST:0.17148  AvgTextLen:39.6  AvgSpecLen:136.8  StepTime:0.53  LR:0.000100\n",
      " | > Step:447/562  GlobalStep:2700  TotalLoss:0.14535  LinearLoss:0.07435  MelLoss:0.07100  StopLoss:0.18955  GradNorm:0.04208  GradNormST:0.36833  AvgTextLen:43.3  AvgSpecLen:145.5  StepTime:0.44  LR:0.000100\n",
      " | > Step:497/562  GlobalStep:2750  TotalLoss:0.14270  LinearLoss:0.07261  MelLoss:0.07008  StopLoss:0.14611  GradNorm:0.04430  GradNormST:0.26837  AvgTextLen:51.0  AvgSpecLen:182.5  StepTime:0.91  LR:0.000100\n",
      " | > Step:547/562  GlobalStep:2800  TotalLoss:0.14376  LinearLoss:0.07733  MelLoss:0.06643  StopLoss:0.10538  GradNorm:0.17028  GradNormST:0.76471  AvgTextLen:57.0  AvgSpecLen:207.6  StepTime:1.73  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:2815  AvgTotalLoss:0.36750  AvgLinearLoss:0.07266  AvgMelLoss:0.06945  AvgStopLoss:0.22539  EpochTime:289.14  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.51502   LinearLoss: 0.07180   MelLoss:0.05886  StopLoss: 0.38437  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.07266   Validation Loss: 0.07793\n",
      "\n",
      " > Epoch 5/1000\n",
      " | > Step:34/562  GlobalStep:2850  TotalLoss:0.13284  LinearLoss:0.06828  MelLoss:0.06456  StopLoss:0.25242  GradNorm:0.14867  GradNormST:1.75727  AvgTextLen:11.1  AvgSpecLen:94.3  StepTime:0.46  LR:0.000100\n",
      " | > Step:84/562  GlobalStep:2900  TotalLoss:0.12935  LinearLoss:0.06636  MelLoss:0.06299  StopLoss:0.25071  GradNorm:0.05467  GradNormST:0.60883  AvgTextLen:17.2  AvgSpecLen:107.5  StepTime:0.49  LR:0.000100\n",
      " | > Step:134/562  GlobalStep:2950  TotalLoss:0.13274  LinearLoss:0.06869  MelLoss:0.06405  StopLoss:0.32282  GradNorm:0.06198  GradNormST:2.13492  AvgTextLen:21.2  AvgSpecLen:123.1  StepTime:0.52  LR:0.000100\n",
      " | > Step:184/562  GlobalStep:3000  TotalLoss:0.14205  LinearLoss:0.07412  MelLoss:0.06793  StopLoss:0.24579  GradNorm:0.05923  GradNormST:0.50238  AvgTextLen:24.6  AvgSpecLen:101.2  StepTime:0.46  LR:0.000100\n",
      " | > Step:234/562  GlobalStep:3050  TotalLoss:0.13825  LinearLoss:0.07110  MelLoss:0.06715  StopLoss:0.25039  GradNorm:0.04980  GradNormST:0.34354  AvgTextLen:28.9  AvgSpecLen:110.5  StepTime:0.43  LR:0.000100\n",
      " | > Step:284/562  GlobalStep:3100  TotalLoss:0.13997  LinearLoss:0.07013  MelLoss:0.06984  StopLoss:0.18360  GradNorm:0.04530  GradNormST:0.75640  AvgTextLen:31.1  AvgSpecLen:113.9  StepTime:0.59  LR:0.000100\n",
      " | > Step:334/562  GlobalStep:3150  TotalLoss:0.14633  LinearLoss:0.07423  MelLoss:0.07210  StopLoss:0.20842  GradNorm:0.11067  GradNormST:0.23378  AvgTextLen:34.8  AvgSpecLen:121.3  StepTime:0.51  LR:0.000100\n",
      " | > Step:384/562  GlobalStep:3200  TotalLoss:0.14818  LinearLoss:0.07490  MelLoss:0.07327  StopLoss:0.20391  GradNorm:0.04164  GradNormST:0.83412  AvgTextLen:39.4  AvgSpecLen:122.4  StepTime:0.47  LR:0.000100\n",
      " | > Step:434/562  GlobalStep:3250  TotalLoss:0.13975  LinearLoss:0.07202  MelLoss:0.06773  StopLoss:0.13035  GradNorm:0.06218  GradNormST:0.79182  AvgTextLen:43.1  AvgSpecLen:172.4  StepTime:0.80  LR:0.000100\n",
      " | > Step:484/562  GlobalStep:3300  TotalLoss:0.14241  LinearLoss:0.07160  MelLoss:0.07081  StopLoss:0.23751  GradNorm:0.05359  GradNormST:0.85755  AvgTextLen:47.9  AvgSpecLen:149.8  StepTime:0.65  LR:0.000100\n",
      " | > Step:534/562  GlobalStep:3350  TotalLoss:0.14996  LinearLoss:0.07499  MelLoss:0.07498  StopLoss:0.15692  GradNorm:0.08090  GradNormST:0.25602  AvgTextLen:53.6  AvgSpecLen:173.1  StepTime:0.60  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:3378  AvgTotalLoss:0.35729  AvgLinearLoss:0.07173  AvgMelLoss:0.06882  AvgStopLoss:0.21673  EpochTime:291.60  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.53866   LinearLoss: 0.06907   MelLoss:0.05868  StopLoss: 0.41091  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.07173   Validation Loss: 0.07554\n",
      "\n",
      " > BEST MODEL (0.07554) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 6/1000\n",
      " | > Step:21/562  GlobalStep:3400  TotalLoss:0.11536  LinearLoss:0.06126  MelLoss:0.05410  StopLoss:0.33135  GradNorm:0.08444  GradNormST:0.30695  AvgTextLen:9.2  AvgSpecLen:86.2  StepTime:0.41  LR:0.000100\n",
      " | > Step:71/562  GlobalStep:3450  TotalLoss:0.13527  LinearLoss:0.06879  MelLoss:0.06648  StopLoss:0.24192  GradNorm:0.08724  GradNormST:0.32949  AvgTextLen:14.6  AvgSpecLen:96.4  StepTime:0.43  LR:0.000100\n",
      " | > Step:121/562  GlobalStep:3500  TotalLoss:0.13440  LinearLoss:0.06982  MelLoss:0.06458  StopLoss:0.20944  GradNorm:0.10154  GradNormST:0.40955  AvgTextLen:20.8  AvgSpecLen:138.4  StepTime:0.52  LR:0.000100\n",
      " | > Step:171/562  GlobalStep:3550  TotalLoss:0.13539  LinearLoss:0.06858  MelLoss:0.06681  StopLoss:0.22663  GradNorm:0.06611  GradNormST:1.32933  AvgTextLen:25.6  AvgSpecLen:109.7  StepTime:0.31  LR:0.000100\n",
      " | > Step:221/562  GlobalStep:3600  TotalLoss:0.13757  LinearLoss:0.06963  MelLoss:0.06794  StopLoss:0.26660  GradNorm:0.08094  GradNormST:0.54531  AvgTextLen:27.5  AvgSpecLen:113.6  StepTime:0.41  LR:0.000100\n",
      " | > Step:271/562  GlobalStep:3650  TotalLoss:0.13660  LinearLoss:0.06927  MelLoss:0.06733  StopLoss:0.19563  GradNorm:0.04629  GradNormST:0.31553  AvgTextLen:29.8  AvgSpecLen:131.3  StepTime:0.56  LR:0.000100\n",
      " | > Step:321/562  GlobalStep:3700  TotalLoss:0.14018  LinearLoss:0.07075  MelLoss:0.06944  StopLoss:0.20635  GradNorm:0.06475  GradNormST:0.32023  AvgTextLen:34.6  AvgSpecLen:141.3  StepTime:0.57  LR:0.000100\n",
      " | > Step:371/562  GlobalStep:3750  TotalLoss:0.14836  LinearLoss:0.07475  MelLoss:0.07362  StopLoss:0.18704  GradNorm:0.09023  GradNormST:0.12905  AvgTextLen:37.7  AvgSpecLen:128.8  StepTime:0.47  LR:0.000100\n",
      " | > Step:421/562  GlobalStep:3800  TotalLoss:0.14457  LinearLoss:0.07225  MelLoss:0.07232  StopLoss:0.22994  GradNorm:0.06607  GradNormST:1.06129  AvgTextLen:40.6  AvgSpecLen:143.0  StepTime:0.40  LR:0.000100\n",
      " | > Step:471/562  GlobalStep:3850  TotalLoss:0.14630  LinearLoss:0.07328  MelLoss:0.07303  StopLoss:0.17920  GradNorm:0.04628  GradNormST:0.12471  AvgTextLen:46.4  AvgSpecLen:159.4  StepTime:0.53  LR:0.000100\n",
      " | > Step:521/562  GlobalStep:3900  TotalLoss:0.14228  LinearLoss:0.07127  MelLoss:0.07102  StopLoss:0.21569  GradNorm:0.06466  GradNormST:1.46998  AvgTextLen:52.2  AvgSpecLen:189.9  StepTime:0.62  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:3941  AvgTotalLoss:0.35107  AvgLinearLoss:0.07060  AvgMelLoss:0.06816  AvgStopLoss:0.21230  EpochTime:288.58  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.48537   LinearLoss: 0.06836   MelLoss:0.05785  StopLoss: 0.35916  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.07060   Validation Loss: 0.07511\n",
      "\n",
      " > BEST MODEL (0.07511) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 7/1000\n",
      " | > Step:8/562  GlobalStep:3950  TotalLoss:0.11564  LinearLoss:0.06633  MelLoss:0.04931  StopLoss:0.29322  GradNorm:0.18196  GradNormST:0.44937  AvgTextLen:6.5  AvgSpecLen:93.7  StepTime:0.51  LR:0.000100\n",
      " | > Step:58/562  GlobalStep:4000  TotalLoss:0.12316  LinearLoss:0.06665  MelLoss:0.05651  StopLoss:0.26318  GradNorm:0.09278  GradNormST:0.70229  AvgTextLen:13.8  AvgSpecLen:90.2  StepTime:0.43  LR:0.000100\n",
      " | > Step:108/562  GlobalStep:4050  TotalLoss:0.13488  LinearLoss:0.07165  MelLoss:0.06323  StopLoss:0.19745  GradNorm:0.08371  GradNormST:0.65978  AvgTextLen:19.0  AvgSpecLen:112.0  StepTime:0.46  LR:0.000100\n",
      " | > Step:158/562  GlobalStep:4100  TotalLoss:0.13255  LinearLoss:0.06759  MelLoss:0.06496  StopLoss:0.19293  GradNorm:0.04828  GradNormST:0.14568  AvgTextLen:23.7  AvgSpecLen:128.6  StepTime:0.54  LR:0.000100\n",
      " | > Step:208/562  GlobalStep:4150  TotalLoss:0.13137  LinearLoss:0.06737  MelLoss:0.06400  StopLoss:0.23296  GradNorm:0.08669  GradNormST:0.96207  AvgTextLen:27.5  AvgSpecLen:132.8  StepTime:0.53  LR:0.000100\n",
      " | > Step:258/562  GlobalStep:4200  TotalLoss:0.13966  LinearLoss:0.07122  MelLoss:0.06844  StopLoss:0.19770  GradNorm:0.08091  GradNormST:0.40563  AvgTextLen:31.1  AvgSpecLen:125.5  StepTime:0.55  LR:0.000100\n",
      " | > Step:308/562  GlobalStep:4250  TotalLoss:0.13666  LinearLoss:0.07038  MelLoss:0.06628  StopLoss:0.20520  GradNorm:0.06113  GradNormST:0.50040  AvgTextLen:33.4  AvgSpecLen:122.4  StepTime:0.47  LR:0.000100\n",
      " | > Step:358/562  GlobalStep:4300  TotalLoss:0.14171  LinearLoss:0.07096  MelLoss:0.07075  StopLoss:0.16157  GradNorm:0.04826  GradNormST:0.30229  AvgTextLen:37.0  AvgSpecLen:144.7  StepTime:0.49  LR:0.000100\n",
      " | > Step:408/562  GlobalStep:4350  TotalLoss:0.14471  LinearLoss:0.07129  MelLoss:0.07342  StopLoss:0.15878  GradNorm:0.04250  GradNormST:0.59243  AvgTextLen:41.3  AvgSpecLen:155.2  StepTime:0.45  LR:0.000100\n",
      " | > Step:458/562  GlobalStep:4400  TotalLoss:0.14465  LinearLoss:0.07301  MelLoss:0.07163  StopLoss:0.14640  GradNorm:0.09273  GradNormST:0.13357  AvgTextLen:46.1  AvgSpecLen:154.4  StepTime:0.57  LR:0.000100\n",
      " | > Step:508/562  GlobalStep:4450  TotalLoss:0.14675  LinearLoss:0.07347  MelLoss:0.07329  StopLoss:0.13054  GradNorm:0.12360  GradNormST:0.70581  AvgTextLen:50.1  AvgSpecLen:155.2  StepTime:0.55  LR:0.000100\n",
      " | > Step:558/562  GlobalStep:4500  TotalLoss:0.13779  LinearLoss:0.06996  MelLoss:0.06782  StopLoss:0.21850  GradNorm:0.07356  GradNormST:1.51249  AvgTextLen:59.5  AvgSpecLen:206.0  StepTime:0.55  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:4504  AvgTotalLoss:0.34680  AvgLinearLoss:0.06975  AvgMelLoss:0.06752  AvgStopLoss:0.20952  EpochTime:288.19  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.49580   LinearLoss: 0.06886   MelLoss:0.05814  StopLoss: 0.36880  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06975   Validation Loss: 0.07521\n",
      "\n",
      " > Epoch 8/1000\n",
      " | > Step:45/562  GlobalStep:4550  TotalLoss:0.11953  LinearLoss:0.06208  MelLoss:0.05745  StopLoss:0.24448  GradNorm:0.07109  GradNormST:0.25973  AvgTextLen:11.6  AvgSpecLen:98.2  StepTime:0.49  LR:0.000100\n",
      " | > Step:95/562  GlobalStep:4600  TotalLoss:0.13537  LinearLoss:0.06767  MelLoss:0.06770  StopLoss:0.24994  GradNorm:0.05991  GradNormST:0.50958  AvgTextLen:17.5  AvgSpecLen:93.8  StepTime:0.47  LR:0.000100\n",
      " | > Step:145/562  GlobalStep:4650  TotalLoss:0.12697  LinearLoss:0.06647  MelLoss:0.06049  StopLoss:0.20002  GradNorm:0.04227  GradNormST:0.18960  AvgTextLen:23.6  AvgSpecLen:113.7  StepTime:0.52  LR:0.000100\n",
      " | > Step:195/562  GlobalStep:4700  TotalLoss:0.14375  LinearLoss:0.07141  MelLoss:0.07234  StopLoss:0.16578  GradNorm:0.04619  GradNormST:0.86609  AvgTextLen:25.7  AvgSpecLen:100.3  StepTime:0.49  LR:0.000100\n",
      " | > Step:245/562  GlobalStep:4750  TotalLoss:0.13538  LinearLoss:0.07188  MelLoss:0.06350  StopLoss:0.24624  GradNorm:0.08467  GradNormST:1.42617  AvgTextLen:28.5  AvgSpecLen:128.0  StepTime:0.69  LR:0.000100\n",
      " | > Step:295/562  GlobalStep:4800  TotalLoss:0.13552  LinearLoss:0.06886  MelLoss:0.06666  StopLoss:0.19912  GradNorm:0.04090  GradNormST:0.29379  AvgTextLen:32.9  AvgSpecLen:131.6  StepTime:0.52  LR:0.000100\n",
      " | > Step:345/562  GlobalStep:4850  TotalLoss:0.13959  LinearLoss:0.06954  MelLoss:0.07006  StopLoss:0.22499  GradNorm:0.05405  GradNormST:0.25325  AvgTextLen:35.4  AvgSpecLen:118.3  StepTime:0.48  LR:0.000100\n",
      " | > Step:395/562  GlobalStep:4900  TotalLoss:0.13297  LinearLoss:0.06753  MelLoss:0.06545  StopLoss:0.21495  GradNorm:0.04529  GradNormST:1.48654  AvgTextLen:40.3  AvgSpecLen:165.3  StepTime:0.50  LR:0.000100\n",
      " | > Step:445/562  GlobalStep:4950  TotalLoss:0.14376  LinearLoss:0.07196  MelLoss:0.07180  StopLoss:0.14384  GradNorm:0.07161  GradNormST:0.32998  AvgTextLen:42.5  AvgSpecLen:150.1  StepTime:0.66  LR:0.000100\n",
      " | > Step:495/562  GlobalStep:5000  TotalLoss:0.14264  LinearLoss:0.07140  MelLoss:0.07124  StopLoss:0.15972  GradNorm:0.04533  GradNormST:0.27970  AvgTextLen:49.0  AvgSpecLen:152.8  StepTime:0.60  LR:0.000100\n",
      " | | > Checkpoint saving : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/checkpoint_5000.pth.tar\n",
      " | > Step:545/562  GlobalStep:5050  TotalLoss:0.14363  LinearLoss:0.07100  MelLoss:0.07264  StopLoss:0.18040  GradNorm:0.02832  GradNormST:0.69177  AvgTextLen:57.7  AvgSpecLen:194.0  StepTime:0.63  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:5067  AvgTotalLoss:0.34220  AvgLinearLoss:0.06909  AvgMelLoss:0.06709  AvgStopLoss:0.20603  EpochTime:289.63  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.48320   LinearLoss: 0.06888   MelLoss:0.05725  StopLoss: 0.35707  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06909   Validation Loss: 0.07549\n",
      "\n",
      " > Epoch 9/1000\n",
      " | > Step:32/562  GlobalStep:5100  TotalLoss:0.12636  LinearLoss:0.06419  MelLoss:0.06216  StopLoss:0.17941  GradNorm:0.04789  GradNormST:2.16325  AvgTextLen:11.5  AvgSpecLen:97.8  StepTime:0.54  LR:0.000100\n",
      " | > Step:82/562  GlobalStep:5150  TotalLoss:0.12630  LinearLoss:0.06369  MelLoss:0.06261  StopLoss:0.30545  GradNorm:0.04555  GradNormST:0.99715  AvgTextLen:17.1  AvgSpecLen:97.4  StepTime:0.46  LR:0.000100\n",
      " | > Step:132/562  GlobalStep:5200  TotalLoss:0.12874  LinearLoss:0.06650  MelLoss:0.06224  StopLoss:0.24969  GradNorm:0.03938  GradNormST:0.24571  AvgTextLen:21.5  AvgSpecLen:109.0  StepTime:0.54  LR:0.000100\n",
      " | > Step:182/562  GlobalStep:5250  TotalLoss:0.13384  LinearLoss:0.06644  MelLoss:0.06740  StopLoss:0.12767  GradNorm:0.06803  GradNormST:0.93155  AvgTextLen:24.9  AvgSpecLen:116.4  StepTime:0.74  LR:0.000100\n",
      " | > Step:232/562  GlobalStep:5300  TotalLoss:0.12786  LinearLoss:0.06477  MelLoss:0.06310  StopLoss:0.28402  GradNorm:0.08394  GradNormST:1.34525  AvgTextLen:28.4  AvgSpecLen:122.1  StepTime:0.48  LR:0.000100\n",
      " | > Step:282/562  GlobalStep:5350  TotalLoss:0.13908  LinearLoss:0.07133  MelLoss:0.06775  StopLoss:0.16899  GradNorm:0.09432  GradNormST:0.17487  AvgTextLen:31.9  AvgSpecLen:120.6  StepTime:0.38  LR:0.000100\n",
      " | > Step:332/562  GlobalStep:5400  TotalLoss:0.13846  LinearLoss:0.07024  MelLoss:0.06822  StopLoss:0.21431  GradNorm:0.07758  GradNormST:0.77434  AvgTextLen:35.7  AvgSpecLen:120.8  StepTime:0.43  LR:0.000100\n",
      " | > Step:382/562  GlobalStep:5450  TotalLoss:0.13731  LinearLoss:0.06894  MelLoss:0.06837  StopLoss:0.25003  GradNorm:0.07558  GradNormST:1.80556  AvgTextLen:39.6  AvgSpecLen:137.6  StepTime:0.60  LR:0.000100\n",
      " | > Step:432/562  GlobalStep:5500  TotalLoss:0.14298  LinearLoss:0.07275  MelLoss:0.07023  StopLoss:0.18811  GradNorm:0.05589  GradNormST:0.09872  AvgTextLen:43.2  AvgSpecLen:149.3  StepTime:0.60  LR:0.000100\n",
      " | > Step:482/562  GlobalStep:5550  TotalLoss:0.14124  LinearLoss:0.07158  MelLoss:0.06966  StopLoss:0.18093  GradNorm:0.03759  GradNormST:0.39234  AvgTextLen:48.0  AvgSpecLen:155.7  StepTime:0.60  LR:0.000100\n",
      " | > Step:532/562  GlobalStep:5600  TotalLoss:0.14109  LinearLoss:0.07037  MelLoss:0.07073  StopLoss:0.17291  GradNorm:0.03140  GradNormST:0.43479  AvgTextLen:53.1  AvgSpecLen:170.0  StepTime:0.39  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:5630  AvgTotalLoss:0.33789  AvgLinearLoss:0.06860  AvgMelLoss:0.06672  AvgStopLoss:0.20257  EpochTime:292.65  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.46621   LinearLoss: 0.06696   MelLoss:0.05617  StopLoss: 0.34308  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06860   Validation Loss: 0.07350\n",
      "\n",
      " > BEST MODEL (0.07350) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 10/1000\n",
      " | > Step:19/562  GlobalStep:5650  TotalLoss:0.11827  LinearLoss:0.06263  MelLoss:0.05564  StopLoss:0.22528  GradNorm:0.06088  GradNormST:0.89972  AvgTextLen:8.9  AvgSpecLen:101.6  StepTime:0.51  LR:0.000100\n",
      " | > Step:69/562  GlobalStep:5700  TotalLoss:0.13046  LinearLoss:0.06563  MelLoss:0.06483  StopLoss:0.23071  GradNorm:0.06092  GradNormST:0.48129  AvgTextLen:14.6  AvgSpecLen:96.5  StepTime:0.27  LR:0.000100\n",
      " | > Step:119/562  GlobalStep:5750  TotalLoss:0.12933  LinearLoss:0.06564  MelLoss:0.06368  StopLoss:0.19174  GradNorm:0.07568  GradNormST:0.61551  AvgTextLen:20.2  AvgSpecLen:104.9  StepTime:0.47  LR:0.000100\n",
      " | > Step:169/562  GlobalStep:5800  TotalLoss:0.13800  LinearLoss:0.07034  MelLoss:0.06766  StopLoss:0.11753  GradNorm:0.16428  GradNormST:1.62000  AvgTextLen:26.1  AvgSpecLen:104.5  StepTime:0.70  LR:0.000100\n",
      " | > Step:219/562  GlobalStep:5850  TotalLoss:0.13683  LinearLoss:0.06895  MelLoss:0.06788  StopLoss:0.19168  GradNorm:0.03924  GradNormST:0.42536  AvgTextLen:27.5  AvgSpecLen:121.3  StepTime:0.50  LR:0.000100\n",
      " | > Step:269/562  GlobalStep:5900  TotalLoss:0.13132  LinearLoss:0.06797  MelLoss:0.06336  StopLoss:0.24499  GradNorm:0.05431  GradNormST:1.29976  AvgTextLen:30.6  AvgSpecLen:115.8  StepTime:0.43  LR:0.000100\n",
      " | > Step:319/562  GlobalStep:5950  TotalLoss:0.13582  LinearLoss:0.06901  MelLoss:0.06682  StopLoss:0.15410  GradNorm:0.05069  GradNormST:0.95067  AvgTextLen:34.2  AvgSpecLen:118.5  StepTime:0.55  LR:0.000100\n",
      " | > Step:369/562  GlobalStep:6000  TotalLoss:0.13132  LinearLoss:0.06683  MelLoss:0.06450  StopLoss:0.21622  GradNorm:0.05176  GradNormST:0.81734  AvgTextLen:37.5  AvgSpecLen:134.7  StepTime:0.50  LR:0.000100\n",
      " | > Step:419/562  GlobalStep:6050  TotalLoss:0.14303  LinearLoss:0.07169  MelLoss:0.07135  StopLoss:0.15602  GradNorm:0.07794  GradNormST:0.14664  AvgTextLen:41.4  AvgSpecLen:150.1  StepTime:0.66  LR:0.000100\n",
      " | > Step:469/562  GlobalStep:6100  TotalLoss:0.14418  LinearLoss:0.07195  MelLoss:0.07224  StopLoss:0.14605  GradNorm:0.06078  GradNormST:0.43888  AvgTextLen:45.7  AvgSpecLen:148.7  StepTime:0.40  LR:0.000100\n",
      " | > Step:519/562  GlobalStep:6150  TotalLoss:0.13980  LinearLoss:0.07015  MelLoss:0.06965  StopLoss:0.15944  GradNorm:0.04438  GradNormST:0.09400  AvgTextLen:50.5  AvgSpecLen:165.3  StepTime:0.51  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:6193  AvgTotalLoss:0.33322  AvgLinearLoss:0.06802  AvgMelLoss:0.06623  AvgStopLoss:0.19897  EpochTime:286.86  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.45098   LinearLoss: 0.06669   MelLoss:0.05515  StopLoss: 0.32914  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06802   Validation Loss: 0.07299\n",
      "\n",
      " > BEST MODEL (0.07299) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 11/1000\n",
      " | > Step:6/562  GlobalStep:6200  TotalLoss:0.11571  LinearLoss:0.06100  MelLoss:0.05471  StopLoss:0.24292  GradNorm:0.10646  GradNormST:2.26100  AvgTextLen:5.5  AvgSpecLen:86.1  StepTime:0.37  LR:0.000100\n",
      " | > Step:56/562  GlobalStep:6250  TotalLoss:0.12247  LinearLoss:0.06429  MelLoss:0.05818  StopLoss:0.22849  GradNorm:0.09472  GradNormST:1.18280  AvgTextLen:14.1  AvgSpecLen:96.5  StepTime:0.41  LR:0.000100\n",
      " | > Step:106/562  GlobalStep:6300  TotalLoss:0.12925  LinearLoss:0.06603  MelLoss:0.06321  StopLoss:0.21402  GradNorm:0.04665  GradNormST:0.28600  AvgTextLen:19.3  AvgSpecLen:102.3  StepTime:0.49  LR:0.000100\n",
      " | > Step:156/562  GlobalStep:6350  TotalLoss:0.13886  LinearLoss:0.06968  MelLoss:0.06918  StopLoss:0.20073  GradNorm:0.10568  GradNormST:0.22391  AvgTextLen:22.8  AvgSpecLen:113.0  StepTime:0.39  LR:0.000100\n",
      " | > Step:206/562  GlobalStep:6400  TotalLoss:0.12879  LinearLoss:0.06469  MelLoss:0.06410  StopLoss:0.21670  GradNorm:0.04619  GradNormST:0.60812  AvgTextLen:26.3  AvgSpecLen:110.2  StepTime:0.37  LR:0.000100\n",
      " | > Step:256/562  GlobalStep:6450  TotalLoss:0.13676  LinearLoss:0.06817  MelLoss:0.06858  StopLoss:0.18772  GradNorm:0.04807  GradNormST:0.51077  AvgTextLen:29.8  AvgSpecLen:115.9  StepTime:0.51  LR:0.000100\n",
      " | > Step:306/562  GlobalStep:6500  TotalLoss:0.13845  LinearLoss:0.07072  MelLoss:0.06773  StopLoss:0.15810  GradNorm:0.07933  GradNormST:0.92818  AvgTextLen:33.2  AvgSpecLen:127.0  StepTime:0.65  LR:0.000100\n",
      " | > Step:356/562  GlobalStep:6550  TotalLoss:0.13706  LinearLoss:0.06835  MelLoss:0.06871  StopLoss:0.18722  GradNorm:0.03911  GradNormST:0.19295  AvgTextLen:36.7  AvgSpecLen:130.6  StepTime:0.49  LR:0.000100\n",
      " | > Step:406/562  GlobalStep:6600  TotalLoss:0.14275  LinearLoss:0.07086  MelLoss:0.07189  StopLoss:0.15193  GradNorm:0.05523  GradNormST:1.36934  AvgTextLen:39.5  AvgSpecLen:117.0  StepTime:0.48  LR:0.000100\n",
      " | > Step:456/562  GlobalStep:6650  TotalLoss:0.14379  LinearLoss:0.07099  MelLoss:0.07279  StopLoss:0.13723  GradNorm:0.05019  GradNormST:0.44233  AvgTextLen:44.6  AvgSpecLen:141.3  StepTime:0.66  LR:0.000100\n",
      " | > Step:506/562  GlobalStep:6700  TotalLoss:0.14139  LinearLoss:0.07071  MelLoss:0.07068  StopLoss:0.12668  GradNorm:0.04197  GradNormST:0.78813  AvgTextLen:50.3  AvgSpecLen:177.9  StepTime:0.79  LR:0.000100\n",
      " | > Step:556/562  GlobalStep:6750  TotalLoss:0.13686  LinearLoss:0.06929  MelLoss:0.06757  StopLoss:0.15516  GradNorm:0.04854  GradNormST:0.26423  AvgTextLen:59.4  AvgSpecLen:198.4  StepTime:0.56  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:6756  AvgTotalLoss:0.33053  AvgLinearLoss:0.06738  AvgMelLoss:0.06580  AvgStopLoss:0.19735  EpochTime:289.68  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.46777   LinearLoss: 0.06792   MelLoss:0.05484  StopLoss: 0.34501  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06738   Validation Loss: 0.07356\n",
      "\n",
      " > Epoch 12/1000\n",
      " | > Step:43/562  GlobalStep:6800  TotalLoss:0.12734  LinearLoss:0.06435  MelLoss:0.06299  StopLoss:0.26713  GradNorm:0.05309  GradNormST:0.23622  AvgTextLen:12.4  AvgSpecLen:81.4  StepTime:0.35  LR:0.000100\n",
      " | > Step:93/562  GlobalStep:6850  TotalLoss:0.13051  LinearLoss:0.06563  MelLoss:0.06488  StopLoss:0.21001  GradNorm:0.08024  GradNormST:0.39382  AvgTextLen:18.3  AvgSpecLen:97.6  StepTime:0.51  LR:0.000100\n",
      " | > Step:143/562  GlobalStep:6900  TotalLoss:0.12628  LinearLoss:0.06438  MelLoss:0.06190  StopLoss:0.24487  GradNorm:0.04582  GradNormST:0.72579  AvgTextLen:21.5  AvgSpecLen:101.0  StepTime:0.50  LR:0.000100\n",
      " | > Step:193/562  GlobalStep:6950  TotalLoss:0.13454  LinearLoss:0.06821  MelLoss:0.06634  StopLoss:0.14052  GradNorm:0.06306  GradNormST:1.15185  AvgTextLen:26.5  AvgSpecLen:107.0  StepTime:0.55  LR:0.000100\n",
      " | > Step:243/562  GlobalStep:7000  TotalLoss:0.13647  LinearLoss:0.06844  MelLoss:0.06804  StopLoss:0.17928  GradNorm:0.04283  GradNormST:0.14520  AvgTextLen:29.9  AvgSpecLen:116.7  StepTime:0.61  LR:0.000100\n",
      " | > Step:293/562  GlobalStep:7050  TotalLoss:0.12934  LinearLoss:0.06463  MelLoss:0.06471  StopLoss:0.23042  GradNorm:0.05109  GradNormST:0.89745  AvgTextLen:31.6  AvgSpecLen:121.9  StepTime:0.66  LR:0.000100\n",
      " | > Step:343/562  GlobalStep:7100  TotalLoss:0.12808  LinearLoss:0.06526  MelLoss:0.06283  StopLoss:0.22485  GradNorm:0.03950  GradNormST:0.92232  AvgTextLen:36.3  AvgSpecLen:147.9  StepTime:0.67  LR:0.000100\n",
      " | > Step:393/562  GlobalStep:7150  TotalLoss:0.13323  LinearLoss:0.06635  MelLoss:0.06688  StopLoss:0.20910  GradNorm:0.05205  GradNormST:1.07693  AvgTextLen:39.7  AvgSpecLen:141.2  StepTime:0.46  LR:0.000100\n",
      " | > Step:443/562  GlobalStep:7200  TotalLoss:0.13406  LinearLoss:0.06746  MelLoss:0.06661  StopLoss:0.19969  GradNorm:0.05018  GradNormST:0.77290  AvgTextLen:43.5  AvgSpecLen:158.2  StepTime:0.43  LR:0.000100\n",
      " | > Step:493/562  GlobalStep:7250  TotalLoss:0.13356  LinearLoss:0.06717  MelLoss:0.06639  StopLoss:0.17630  GradNorm:0.03807  GradNormST:0.31007  AvgTextLen:48.4  AvgSpecLen:163.6  StepTime:0.73  LR:0.000100\n",
      " | > Step:543/562  GlobalStep:7300  TotalLoss:0.14151  LinearLoss:0.07048  MelLoss:0.07103  StopLoss:0.14816  GradNorm:0.04295  GradNormST:0.32171  AvgTextLen:55.3  AvgSpecLen:178.1  StepTime:0.67  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:7319  AvgTotalLoss:0.32843  AvgLinearLoss:0.06683  AvgMelLoss:0.06542  AvgStopLoss:0.19617  EpochTime:291.44  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.45727   LinearLoss: 0.06992   MelLoss:0.05516  StopLoss: 0.33220  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06683   Validation Loss: 0.07635\n",
      "\n",
      " > Epoch 13/1000\n",
      " | > Step:30/562  GlobalStep:7350  TotalLoss:0.11941  LinearLoss:0.06308  MelLoss:0.05633  StopLoss:0.25618  GradNorm:0.09366  GradNormST:0.89071  AvgTextLen:10.3  AvgSpecLen:106.5  StepTime:0.49  LR:0.000100\n",
      " | > Step:80/562  GlobalStep:7400  TotalLoss:0.11936  LinearLoss:0.06252  MelLoss:0.05684  StopLoss:0.26754  GradNorm:0.09099  GradNormST:0.25491  AvgTextLen:16.6  AvgSpecLen:93.7  StepTime:0.33  LR:0.000100\n",
      " | > Step:130/562  GlobalStep:7450  TotalLoss:0.12735  LinearLoss:0.06527  MelLoss:0.06209  StopLoss:0.19781  GradNorm:0.04340  GradNormST:0.19363  AvgTextLen:20.7  AvgSpecLen:119.3  StepTime:0.54  LR:0.000100\n",
      " | > Step:180/562  GlobalStep:7500  TotalLoss:0.12479  LinearLoss:0.06415  MelLoss:0.06065  StopLoss:0.14409  GradNorm:0.04565  GradNormST:1.15791  AvgTextLen:25.2  AvgSpecLen:138.2  StepTime:0.74  LR:0.000100\n",
      " | > Step:230/562  GlobalStep:7550  TotalLoss:0.12671  LinearLoss:0.06439  MelLoss:0.06232  StopLoss:0.23817  GradNorm:0.06025  GradNormST:0.17890  AvgTextLen:29.2  AvgSpecLen:109.2  StepTime:0.41  LR:0.000100\n",
      " | > Step:280/562  GlobalStep:7600  TotalLoss:0.13530  LinearLoss:0.06686  MelLoss:0.06844  StopLoss:0.15811  GradNorm:0.09443  GradNormST:0.72943  AvgTextLen:31.3  AvgSpecLen:123.3  StepTime:0.57  LR:0.000100\n",
      " | > Step:330/562  GlobalStep:7650  TotalLoss:0.13335  LinearLoss:0.06736  MelLoss:0.06599  StopLoss:0.21729  GradNorm:0.05025  GradNormST:1.24246  AvgTextLen:35.5  AvgSpecLen:126.2  StepTime:0.49  LR:0.000100\n",
      " | > Step:380/562  GlobalStep:7700  TotalLoss:0.13707  LinearLoss:0.06772  MelLoss:0.06935  StopLoss:0.14412  GradNorm:0.04735  GradNormST:0.23956  AvgTextLen:38.7  AvgSpecLen:133.9  StepTime:0.43  LR:0.000100\n",
      " | > Step:430/562  GlobalStep:7750  TotalLoss:0.13210  LinearLoss:0.06651  MelLoss:0.06559  StopLoss:0.18101  GradNorm:0.04334  GradNormST:0.23827  AvgTextLen:41.8  AvgSpecLen:165.3  StepTime:0.82  LR:0.000100\n",
      " | > Step:480/562  GlobalStep:7800  TotalLoss:0.13824  LinearLoss:0.06981  MelLoss:0.06843  StopLoss:0.16243  GradNorm:0.05046  GradNormST:0.40220  AvgTextLen:47.0  AvgSpecLen:155.5  StepTime:0.63  LR:0.000100\n",
      " | > Step:530/562  GlobalStep:7850  TotalLoss:0.13894  LinearLoss:0.06895  MelLoss:0.06999  StopLoss:0.16367  GradNorm:0.03894  GradNormST:0.31817  AvgTextLen:53.6  AvgSpecLen:165.7  StepTime:0.39  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:7882  AvgTotalLoss:0.32801  AvgLinearLoss:0.06645  AvgMelLoss:0.06517  AvgStopLoss:0.19639  EpochTime:289.00  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.44693   LinearLoss: 0.06784   MelLoss:0.05472  StopLoss: 0.32437  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06645   Validation Loss: 0.07558\n",
      "\n",
      " > Epoch 14/1000\n",
      " | > Step:17/562  GlobalStep:7900  TotalLoss:0.10788  LinearLoss:0.05839  MelLoss:0.04949  StopLoss:0.37161  GradNorm:0.05656  GradNormST:3.19916  AvgTextLen:9.1  AvgSpecLen:93.1  StepTime:0.38  LR:0.000100\n",
      " | > Step:67/562  GlobalStep:7950  TotalLoss:0.12685  LinearLoss:0.06604  MelLoss:0.06082  StopLoss:0.18832  GradNorm:0.06906  GradNormST:1.96861  AvgTextLen:14.7  AvgSpecLen:106.5  StepTime:0.53  LR:0.000100\n",
      " | > Step:117/562  GlobalStep:8000  TotalLoss:0.12735  LinearLoss:0.06481  MelLoss:0.06253  StopLoss:0.23940  GradNorm:0.06251  GradNormST:0.67633  AvgTextLen:19.6  AvgSpecLen:97.3  StepTime:0.39  LR:0.000100\n",
      " | > Step:167/562  GlobalStep:8050  TotalLoss:0.13384  LinearLoss:0.06762  MelLoss:0.06622  StopLoss:0.16737  GradNorm:0.05618  GradNormST:0.49965  AvgTextLen:23.8  AvgSpecLen:100.3  StepTime:0.47  LR:0.000100\n",
      " | > Step:217/562  GlobalStep:8100  TotalLoss:0.12259  LinearLoss:0.06319  MelLoss:0.05940  StopLoss:0.18661  GradNorm:0.04176  GradNormST:0.72831  AvgTextLen:27.8  AvgSpecLen:120.1  StepTime:0.70  LR:0.000100\n",
      " | > Step:267/562  GlobalStep:8150  TotalLoss:0.13572  LinearLoss:0.06787  MelLoss:0.06784  StopLoss:0.14967  GradNorm:0.06011  GradNormST:0.46991  AvgTextLen:31.0  AvgSpecLen:118.6  StepTime:0.63  LR:0.000100\n",
      " | > Step:317/562  GlobalStep:8200  TotalLoss:0.12710  LinearLoss:0.06429  MelLoss:0.06281  StopLoss:0.22169  GradNorm:0.04864  GradNormST:0.34326  AvgTextLen:33.7  AvgSpecLen:116.3  StepTime:0.53  LR:0.000100\n",
      " | > Step:367/562  GlobalStep:8250  TotalLoss:0.13489  LinearLoss:0.06751  MelLoss:0.06738  StopLoss:0.19053  GradNorm:0.03574  GradNormST:0.96105  AvgTextLen:37.7  AvgSpecLen:143.1  StepTime:0.43  LR:0.000100\n",
      " | > Step:417/562  GlobalStep:8300  TotalLoss:0.13381  LinearLoss:0.06695  MelLoss:0.06686  StopLoss:0.14779  GradNorm:0.03888  GradNormST:0.41163  AvgTextLen:41.7  AvgSpecLen:143.6  StepTime:0.78  LR:0.000100\n",
      " | > Step:467/562  GlobalStep:8350  TotalLoss:0.13497  LinearLoss:0.06804  MelLoss:0.06693  StopLoss:0.21858  GradNorm:0.04459  GradNormST:1.29757  AvgTextLen:45.7  AvgSpecLen:156.1  StepTime:0.50  LR:0.000100\n",
      " | > Step:517/562  GlobalStep:8400  TotalLoss:0.13680  LinearLoss:0.06725  MelLoss:0.06955  StopLoss:0.18665  GradNorm:0.03022  GradNormST:0.75680  AvgTextLen:52.0  AvgSpecLen:168.8  StepTime:0.54  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:8445  AvgTotalLoss:0.32484  AvgLinearLoss:0.06607  AvgMelLoss:0.06488  AvgStopLoss:0.19388  EpochTime:289.18  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.45520   LinearLoss: 0.07436   MelLoss:0.05524  StopLoss: 0.32561  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06607   Validation Loss: 0.07849\n",
      "\n",
      " > Epoch 15/1000\n",
      " | > Step:4/562  GlobalStep:8450  TotalLoss:0.12329  LinearLoss:0.06306  MelLoss:0.06023  StopLoss:0.24019  GradNorm:0.09678  GradNormST:0.52162  AvgTextLen:6.4  AvgSpecLen:80.7  StepTime:0.27  LR:0.000100\n",
      " | > Step:54/562  GlobalStep:8500  TotalLoss:0.11826  LinearLoss:0.06158  MelLoss:0.05669  StopLoss:0.24357  GradNorm:0.05581  GradNormST:0.63363  AvgTextLen:13.5  AvgSpecLen:94.0  StepTime:0.30  LR:0.000100\n",
      " | > Step:104/562  GlobalStep:8550  TotalLoss:0.12668  LinearLoss:0.06461  MelLoss:0.06207  StopLoss:0.18385  GradNorm:0.06066  GradNormST:1.37385  AvgTextLen:18.6  AvgSpecLen:107.7  StepTime:0.46  LR:0.000100\n",
      " | > Step:154/562  GlobalStep:8600  TotalLoss:0.12982  LinearLoss:0.06621  MelLoss:0.06361  StopLoss:0.17893  GradNorm:0.04672  GradNormST:0.37634  AvgTextLen:22.8  AvgSpecLen:108.8  StepTime:0.34  LR:0.000100\n",
      " | > Step:204/562  GlobalStep:8650  TotalLoss:0.13099  LinearLoss:0.06586  MelLoss:0.06513  StopLoss:0.14362  GradNorm:0.06396  GradNormST:1.01067  AvgTextLen:26.8  AvgSpecLen:100.3  StepTime:0.55  LR:0.000100\n",
      " | > Step:254/562  GlobalStep:8700  TotalLoss:0.13775  LinearLoss:0.07011  MelLoss:0.06764  StopLoss:0.14991  GradNorm:0.07068  GradNormST:1.17809  AvgTextLen:30.0  AvgSpecLen:117.6  StepTime:0.49  LR:0.000100\n",
      " | > Step:304/562  GlobalStep:8750  TotalLoss:0.13421  LinearLoss:0.06645  MelLoss:0.06776  StopLoss:0.14683  GradNorm:0.08311  GradNormST:0.86849  AvgTextLen:33.1  AvgSpecLen:132.9  StepTime:0.53  LR:0.000100\n",
      " | > Step:354/562  GlobalStep:8800  TotalLoss:0.13825  LinearLoss:0.06840  MelLoss:0.06985  StopLoss:0.12186  GradNorm:0.04691  GradNormST:1.16504  AvgTextLen:36.4  AvgSpecLen:127.6  StepTime:0.68  LR:0.000100\n",
      " | > Step:404/562  GlobalStep:8850  TotalLoss:0.13785  LinearLoss:0.06826  MelLoss:0.06959  StopLoss:0.17434  GradNorm:0.04100  GradNormST:0.60220  AvgTextLen:41.1  AvgSpecLen:140.5  StepTime:0.49  LR:0.000100\n",
      " | > Step:454/562  GlobalStep:8900  TotalLoss:0.13806  LinearLoss:0.06803  MelLoss:0.07003  StopLoss:0.11767  GradNorm:0.05262  GradNormST:0.68302  AvgTextLen:43.9  AvgSpecLen:144.2  StepTime:0.62  LR:0.000100\n",
      " | > Step:504/562  GlobalStep:8950  TotalLoss:0.13506  LinearLoss:0.06737  MelLoss:0.06770  StopLoss:0.11918  GradNorm:0.02955  GradNormST:0.66683  AvgTextLen:50.3  AvgSpecLen:167.8  StepTime:0.86  LR:0.000100\n",
      " | > Step:554/562  GlobalStep:9000  TotalLoss:0.13531  LinearLoss:0.06731  MelLoss:0.06799  StopLoss:0.14953  GradNorm:0.05604  GradNormST:0.45959  AvgTextLen:59.6  AvgSpecLen:199.2  StepTime:0.74  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:9008  AvgTotalLoss:0.32322  AvgLinearLoss:0.06576  AvgMelLoss:0.06467  AvgStopLoss:0.19279  EpochTime:289.22  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.47215   LinearLoss: 0.06697   MelLoss:0.05540  StopLoss: 0.34978  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06576   Validation Loss: 0.07481\n",
      "\n",
      " > Epoch 16/1000\n",
      " | > Step:41/562  GlobalStep:9050  TotalLoss:0.11839  LinearLoss:0.06345  MelLoss:0.05494  StopLoss:0.26695  GradNorm:0.06714  GradNormST:1.87496  AvgTextLen:14.7  AvgSpecLen:86.5  StepTime:0.40  LR:0.000100\n",
      " | > Step:91/562  GlobalStep:9100  TotalLoss:0.12541  LinearLoss:0.06236  MelLoss:0.06305  StopLoss:0.31474  GradNorm:0.05097  GradNormST:2.00675  AvgTextLen:17.4  AvgSpecLen:101.2  StepTime:0.44  LR:0.000100\n",
      " | > Step:141/562  GlobalStep:9150  TotalLoss:0.12920  LinearLoss:0.06639  MelLoss:0.06281  StopLoss:0.14514  GradNorm:0.04443  GradNormST:0.98894  AvgTextLen:22.0  AvgSpecLen:113.2  StepTime:0.35  LR:0.000100\n",
      " | > Step:191/562  GlobalStep:9200  TotalLoss:0.12666  LinearLoss:0.06566  MelLoss:0.06101  StopLoss:0.21943  GradNorm:0.08853  GradNormST:0.46917  AvgTextLen:25.5  AvgSpecLen:109.5  StepTime:0.42  LR:0.000100\n",
      " | > Step:241/562  GlobalStep:9250  TotalLoss:0.13021  LinearLoss:0.06658  MelLoss:0.06363  StopLoss:0.17605  GradNorm:0.04329  GradNormST:0.18500  AvgTextLen:29.4  AvgSpecLen:131.6  StepTime:0.49  LR:0.000100\n",
      " | > Step:291/562  GlobalStep:9300  TotalLoss:0.13573  LinearLoss:0.06618  MelLoss:0.06955  StopLoss:0.19146  GradNorm:0.05946  GradNormST:0.43345  AvgTextLen:32.1  AvgSpecLen:126.7  StepTime:0.53  LR:0.000100\n",
      " | > Step:341/562  GlobalStep:9350  TotalLoss:0.13741  LinearLoss:0.06757  MelLoss:0.06985  StopLoss:0.18631  GradNorm:0.04619  GradNormST:0.41256  AvgTextLen:35.4  AvgSpecLen:123.0  StepTime:0.33  LR:0.000100\n",
      " | > Step:391/562  GlobalStep:9400  TotalLoss:0.14208  LinearLoss:0.06936  MelLoss:0.07272  StopLoss:0.16441  GradNorm:0.03527  GradNormST:0.39870  AvgTextLen:40.3  AvgSpecLen:133.6  StepTime:0.38  LR:0.000100\n",
      " | > Step:441/562  GlobalStep:9450  TotalLoss:0.13282  LinearLoss:0.06769  MelLoss:0.06513  StopLoss:0.18771  GradNorm:0.06723  GradNormST:0.74097  AvgTextLen:43.8  AvgSpecLen:154.8  StepTime:0.54  LR:0.000100\n",
      " | > Step:491/562  GlobalStep:9500  TotalLoss:0.13899  LinearLoss:0.06884  MelLoss:0.07015  StopLoss:0.15606  GradNorm:0.07813  GradNormST:0.39753  AvgTextLen:48.8  AvgSpecLen:147.9  StepTime:0.46  LR:0.000100\n",
      " | > Step:541/562  GlobalStep:9550  TotalLoss:0.14126  LinearLoss:0.06936  MelLoss:0.07191  StopLoss:0.16680  GradNorm:0.06280  GradNormST:0.37690  AvgTextLen:55.0  AvgSpecLen:169.2  StepTime:0.64  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:9571  AvgTotalLoss:0.32017  AvgLinearLoss:0.06550  AvgMelLoss:0.06448  AvgStopLoss:0.19020  EpochTime:291.20  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.44223   LinearLoss: 0.06565   MelLoss:0.05400  StopLoss: 0.32259  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06550   Validation Loss: 0.07283\n",
      "\n",
      " > BEST MODEL (0.07283) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 17/1000\n",
      " | > Step:28/562  GlobalStep:9600  TotalLoss:0.11041  LinearLoss:0.05792  MelLoss:0.05249  StopLoss:0.29259  GradNorm:0.06148  GradNormST:0.75869  AvgTextLen:10.1  AvgSpecLen:95.8  StepTime:0.40  LR:0.000100\n",
      " | > Step:78/562  GlobalStep:9650  TotalLoss:0.11785  LinearLoss:0.06064  MelLoss:0.05721  StopLoss:0.24616  GradNorm:0.05412  GradNormST:1.36117  AvgTextLen:15.9  AvgSpecLen:98.4  StepTime:0.55  LR:0.000100\n",
      " | > Step:128/562  GlobalStep:9700  TotalLoss:0.12240  LinearLoss:0.06170  MelLoss:0.06070  StopLoss:0.21152  GradNorm:0.05427  GradNormST:0.10625  AvgTextLen:20.6  AvgSpecLen:102.0  StepTime:0.43  LR:0.000100\n",
      " | > Step:178/562  GlobalStep:9750  TotalLoss:0.12350  LinearLoss:0.06211  MelLoss:0.06139  StopLoss:0.19097  GradNorm:0.03137  GradNormST:0.39437  AvgTextLen:24.3  AvgSpecLen:98.9  StepTime:0.50  LR:0.000100\n",
      " | > Step:228/562  GlobalStep:9800  TotalLoss:0.12347  LinearLoss:0.06370  MelLoss:0.05976  StopLoss:0.23087  GradNorm:0.05956  GradNormST:0.42320  AvgTextLen:28.6  AvgSpecLen:124.9  StepTime:0.56  LR:0.000100\n",
      " | > Step:278/562  GlobalStep:9850  TotalLoss:0.12977  LinearLoss:0.06573  MelLoss:0.06404  StopLoss:0.20873  GradNorm:0.04891  GradNormST:0.45893  AvgTextLen:30.8  AvgSpecLen:111.4  StepTime:0.48  LR:0.000100\n",
      " | > Step:328/562  GlobalStep:9900  TotalLoss:0.13287  LinearLoss:0.06692  MelLoss:0.06596  StopLoss:0.14603  GradNorm:0.04894  GradNormST:0.14966  AvgTextLen:34.0  AvgSpecLen:136.3  StepTime:0.65  LR:0.000100\n",
      " | > Step:378/562  GlobalStep:9950  TotalLoss:0.13239  LinearLoss:0.06601  MelLoss:0.06638  StopLoss:0.14352  GradNorm:0.03386  GradNormST:0.59587  AvgTextLen:38.4  AvgSpecLen:134.6  StepTime:0.53  LR:0.000100\n",
      " | > Step:428/562  GlobalStep:10000  TotalLoss:0.14052  LinearLoss:0.06953  MelLoss:0.07100  StopLoss:0.14518  GradNorm:0.03738  GradNormST:0.85140  AvgTextLen:41.8  AvgSpecLen:141.8  StepTime:0.49  LR:0.000100\n",
      " | | > Checkpoint saving : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/checkpoint_10000.pth.tar\n",
      " | > Step:478/562  GlobalStep:10050  TotalLoss:0.13008  LinearLoss:0.06557  MelLoss:0.06451  StopLoss:0.13716  GradNorm:0.06551  GradNormST:0.55047  AvgTextLen:46.9  AvgSpecLen:156.4  StepTime:0.83  LR:0.000100\n",
      " | > Step:528/562  GlobalStep:10100  TotalLoss:0.13543  LinearLoss:0.06694  MelLoss:0.06849  StopLoss:0.12067  GradNorm:0.06891  GradNormST:0.10693  AvgTextLen:53.9  AvgSpecLen:161.7  StepTime:0.61  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:10134  AvgTotalLoss:0.31768  AvgLinearLoss:0.06530  AvgMelLoss:0.06430  AvgStopLoss:0.18808  EpochTime:287.29  AvgStepTime:0.51\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.46036   LinearLoss: 0.06397   MelLoss:0.05503  StopLoss: 0.34136  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06530   Validation Loss: 0.07077\n",
      "\n",
      " > BEST MODEL (0.07077) : /vm/TTS/models/cartman_models/queue-May-27-2019_04+22PM-59bbdb3/best_model.pth.tar\n",
      "\n",
      " > Epoch 18/1000\n",
      " | > Step:15/562  GlobalStep:10150  TotalLoss:0.10451  LinearLoss:0.05576  MelLoss:0.04875  StopLoss:0.37428  GradNorm:0.05782  GradNormST:2.89203  AvgTextLen:6.0  AvgSpecLen:89.2  StepTime:0.30  LR:0.000100\n",
      " | > Step:65/562  GlobalStep:10200  TotalLoss:0.11720  LinearLoss:0.06144  MelLoss:0.05576  StopLoss:0.23953  GradNorm:0.04604  GradNormST:0.58098  AvgTextLen:14.3  AvgSpecLen:100.9  StepTime:0.44  LR:0.000100\n",
      " | > Step:115/562  GlobalStep:10250  TotalLoss:0.12271  LinearLoss:0.06125  MelLoss:0.06147  StopLoss:0.20667  GradNorm:0.07919  GradNormST:0.85955  AvgTextLen:19.9  AvgSpecLen:94.2  StepTime:0.33  LR:0.000100\n",
      " | > Step:165/562  GlobalStep:10300  TotalLoss:0.12300  LinearLoss:0.06225  MelLoss:0.06075  StopLoss:0.29677  GradNorm:0.03843  GradNormST:2.24929  AvgTextLen:23.6  AvgSpecLen:104.1  StepTime:0.31  LR:0.000100\n",
      " | > Step:215/562  GlobalStep:10350  TotalLoss:0.12894  LinearLoss:0.06533  MelLoss:0.06361  StopLoss:0.21088  GradNorm:0.05608  GradNormST:0.34571  AvgTextLen:27.7  AvgSpecLen:112.8  StepTime:0.41  LR:0.000100\n",
      " | > Step:265/562  GlobalStep:10400  TotalLoss:0.13489  LinearLoss:0.06681  MelLoss:0.06807  StopLoss:0.18431  GradNorm:0.05552  GradNormST:0.27296  AvgTextLen:31.7  AvgSpecLen:127.2  StepTime:0.65  LR:0.000100\n",
      " | > Step:315/562  GlobalStep:10450  TotalLoss:0.12697  LinearLoss:0.06528  MelLoss:0.06169  StopLoss:0.09422  GradNorm:0.07311  GradNormST:1.24907  AvgTextLen:34.0  AvgSpecLen:144.1  StepTime:1.03  LR:0.000100\n",
      " | > Step:365/562  GlobalStep:10500  TotalLoss:0.13137  LinearLoss:0.06634  MelLoss:0.06504  StopLoss:0.10536  GradNorm:0.04208  GradNormST:0.56615  AvgTextLen:37.0  AvgSpecLen:134.1  StepTime:0.87  LR:0.000100\n",
      " | > Step:415/562  GlobalStep:10550  TotalLoss:0.12736  LinearLoss:0.06328  MelLoss:0.06408  StopLoss:0.18957  GradNorm:0.03876  GradNormST:0.70552  AvgTextLen:41.2  AvgSpecLen:148.9  StepTime:0.63  LR:0.000100\n",
      " | > Step:465/562  GlobalStep:10600  TotalLoss:0.13517  LinearLoss:0.06644  MelLoss:0.06873  StopLoss:0.12155  GradNorm:0.05347  GradNormST:0.68506  AvgTextLen:46.2  AvgSpecLen:157.6  StepTime:0.73  LR:0.000100\n",
      " | > Step:515/562  GlobalStep:10650  TotalLoss:0.12955  LinearLoss:0.06370  MelLoss:0.06585  StopLoss:0.21439  GradNorm:0.03361  GradNormST:1.19130  AvgTextLen:51.2  AvgSpecLen:172.5  StepTime:0.43  LR:0.000100\n",
      " | > EPOCH END -- GlobalStep:10697  AvgTotalLoss:0.31444  AvgLinearLoss:0.06503  AvgMelLoss:0.06409  AvgStopLoss:0.18532  EpochTime:291.94  AvgStepTime:0.52\n",
      "\n",
      " > Validation\n",
      " | > TotalLoss: 0.42454   LinearLoss: 0.06542   MelLoss:0.05413  StopLoss: 0.30499  \n",
      " | > Synthesizing test sentences\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "   | > Decoder stopped with 'max_decoder_steps\n",
      "/vm/tf-py3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      " | > Training Loss: 0.06503   Validation Loss: 0.07185\n",
      "\n",
      " > Epoch 19/1000\n",
      " | > Step:2/562  GlobalStep:10700  TotalLoss:0.11992  LinearLoss:0.06280  MelLoss:0.05713  StopLoss:0.25569  GradNorm:0.07651  GradNormST:0.37380  AvgTextLen:5.8  AvgSpecLen:79.0  StepTime:0.38  LR:0.000100\n",
      " | > Step:52/562  GlobalStep:10750  TotalLoss:0.12048  LinearLoss:0.06203  MelLoss:0.05845  StopLoss:0.22776  GradNorm:0.05325  GradNormST:0.18967  AvgTextLen:14.0  AvgSpecLen:94.8  StepTime:0.36  LR:0.000100\n",
      " | > Step:102/562  GlobalStep:10800  TotalLoss:0.12380  LinearLoss:0.06321  MelLoss:0.06059  StopLoss:0.21473  GradNorm:0.04518  GradNormST:0.74038  AvgTextLen:18.1  AvgSpecLen:107.6  StepTime:0.41  LR:0.000100\n",
      " | > Step:152/562  GlobalStep:10850  TotalLoss:0.12708  LinearLoss:0.06544  MelLoss:0.06164  StopLoss:0.17086  GradNorm:0.05247  GradNormST:0.34968  AvgTextLen:22.7  AvgSpecLen:109.3  StepTime:0.66  LR:0.000100\n",
      " | > Step:202/562  GlobalStep:10900  TotalLoss:0.13169  LinearLoss:0.06541  MelLoss:0.06628  StopLoss:0.25865  GradNorm:0.05019  GradNormST:1.12481  AvgTextLen:26.3  AvgSpecLen:108.9  StepTime:0.38  LR:0.000100\n",
      " | > Step:252/562  GlobalStep:10950  TotalLoss:0.12753  LinearLoss:0.06357  MelLoss:0.06397  StopLoss:0.19416  GradNorm:0.05131  GradNormST:0.28662  AvgTextLen:30.2  AvgSpecLen:117.5  StepTime:0.56  LR:0.000100\n"
     ]
    }
   ],
   "source": [
    "cd /vm/TTS\n",
    "python train.py --config_path config.json\n",
    "#start tensorboard in another terminal\n",
    "#tensorboard --logdir=my_run:<output_path in config.json>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "python train.py --config_path config.json --restore_path /vm/TTS/models/ljspeech_models/queue-April-26-2019_03+46PM-59bbdb3\n",
    "#/path/to/your/model.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"hello TensorFlow!\")\n",
    "sess=tf.Session() \n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

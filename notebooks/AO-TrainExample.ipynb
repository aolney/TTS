{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Mozilla TTS Training Example\n",
    "\n",
    "Adapted [this gist](https://gist.github.com/erogol/97516ad65b44dbddb8cd694953187c5b) for [SoS notebook](https://vatlab.github.io/sos-docs/).\n",
    "\n",
    "Assumes you have already [cloned TTS](https://github.com/mozilla/TTS) and done `apt install espeak`\n",
    "\n",
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "exit #comment to allow execution\n",
    "wget http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
    "tar -xjf LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "exit #comment to allow execution\n",
    "shuf LJSpeech-1.1/metadata.csv > LJSpeech-1.1/metadata_shuf.csv\n",
    "head -n 12000 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_train.csv\n",
    "tail -n 1100 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_val.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Create config file for this training data\n",
    "\n",
    "Some of my local paths are hardcoded below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "#exit #comment to allow execution\n",
    "cd /vm/TTS\n",
    "cp config.json \"config.json.$(date +%Y%m%d)\"\n",
    "cat > config.json << EOM\n",
    "{\n",
    "    \"run_name\": \"mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking\",\n",
    "    \"run_description\": \"using forward attention, with original prenet, loss masking,separate stopnet, sigmoid. Compare this with 4817. Pytorch DPP\",\n",
    "\n",
    "    \"audio\":{\n",
    "        // Audio processing parameters\n",
    "        \"num_mels\": 80,         // size of the mel spec frame. \n",
    "        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\n",
    "        \"sample_rate\": 22050,   // DATASET-RELATED: wav sample-rate. If different than the original data, it is resampled.\n",
    "        \"frame_length_ms\": 50,  // stft window length in ms.\n",
    "        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\n",
    "        \"preemphasis\": 0.98,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\n",
    "        \"min_level_db\": -100,   // normalization range\n",
    "        \"ref_level_db\": 20,     // reference level db, theoretically 20db is the sound of air.\n",
    "        \"power\": 1.5,           // value to sharpen wav signals after GL algorithm.\n",
    "        \"griffin_lim_iters\": 60,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\n",
    "        // Normalization parameters\n",
    "        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\n",
    "        \"symmetric_norm\": false, // move normalization to range [-1, 1]\n",
    "        \"max_norm\": 1,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\n",
    "        \"clip_norm\": true,      // clip normalized values into the range.\n",
    "        \"mel_fmin\": 0.0,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\n",
    "        \"mel_fmax\": 8000.0,        // maximum freq level for mel-spec. Tune for dataset!!\n",
    "        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\n",
    "    },\n",
    "\n",
    "    \"distributed\":{\n",
    "        \"backend\": \"nccl\",\n",
    "        \"url\": \"tcp:\\/\\/localhost:54321\"\n",
    "    },\n",
    "\n",
    "    \"reinit_layers\": [],\n",
    "\n",
    "    \"model\": \"Tacotron2\",          // one of the model in models/    \n",
    "    \"grad_clip\": 1,                // upper limit for gradients for clipping.\n",
    "    \"epochs\": 1000,                // total number of epochs to train.\n",
    "    \"lr\": 0.0001,                  // Initial learning rate. If Noam decay is active, maximum learning rate.\n",
    "    \"lr_decay\": false,             // if true, Noam learning rate decaying is applied through training.\n",
    "    \"warmup_steps\": 4000,          // Noam decay steps to increase the learning rate from 0 to \"lr\"\n",
    "    \"windowing\": false,            // Enables attention windowing. Used only in eval mode.\n",
    "    \"memory_size\": 5,              // ONLY TACOTRON - memory queue size used to queue network predictions to feed autoregressive connection. Useful if r < 5. \n",
    "    \"attention_norm\": \"sigmoid\",   // softmax or sigmoid. Suggested to use softmax for Tacotron2 and sigmoid for Tacotron.\n",
    "    \"prenet_type\": \"original\",     // ONLY TACOTRON2 - \"original\" or \"bn\".\n",
    "    \"prenet_dropout\": true,        // ONLY TACOTRON2 - enable/disable dropout at prenet. \n",
    "    \"use_forward_attn\": true,      // ONLY TACOTRON2 - if it uses forward attention. In general, it aligns faster.\n",
    "    \"transition_agent\": false,     // ONLY TACOTRON2 - enable/disable transition agent of forward attention.\n",
    "    \"location_attn\": false,        // ONLY TACOTRON2 - enable_disable location sensitive attention. It is enabled for TACOTRON by default.\n",
    "    \"loss_masking\": true,         // enable / disable loss masking against the sequence padding.\n",
    "    \"enable_eos_bos_chars\": false, // enable/disable beginning of sentence and end of sentence chars.\n",
    "    \"stopnet\": true,               // Train stopnet predicting the end of synthesis. \n",
    "    \"separate_stopnet\": true,     // Train stopnet seperately if 'stopnet==true'. It prevents stopnet loss to influence the rest of the model. It causes a better model, but it trains SLOWER.\n",
    "    \"tb_model_param_stats\": false,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging. \n",
    "    \n",
    "    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention.\n",
    "    \"eval_batch_size\":16,   \n",
    "    \"r\": 1,                 // Number of frames to predict for step.\n",
    "    \"wd\": 0.000001,         // Weight decay weight.\n",
    "    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\n",
    "    \"save_step\": 1000,      // Number of training steps expected to save traning stats and checkpoints.\n",
    "    \"print_step\": 10,       // Number of steps to log traning on console.\n",
    "    \"batch_group_size\": 0,  //Number of batches to shuffle after bucketing.\n",
    "\n",
    "    \"run_eval\": true,\n",
    "    \"test_delay_epochs\": 5,  //Until attention is aligned, testing only wastes computation time.\n",
    "    \"test_sentences_file\": null,  // set a file to load sentences to be used for testing. If it is null then we use default english sentences.\n",
    "    \"data_path\": \"/vm/LJSpeech-1.1/\",  // DATASET-RELATED: can overwritten from command argument\n",
    "    \"meta_file_train\": \"metadata_train.csv\",       // DATASET-RELATED: metafile for training dataloader.\n",
    "    \"meta_file_val\": \"metadata_val.csv\",    // DATASET-RELATED: metafile for evaluation dataloader.\n",
    "    \"dataset\": \"ljspeech\",       // DATASET-RELATED: one of TTS.dataset.preprocessors depending on your target dataset. Use \"tts_cache\" for pre-computed dataset by extract_features.py\n",
    "    \"min_seq_len\": 0,       // DATASET-RELATED: minimum text length to use in training\n",
    "    \"max_seq_len\": 150,     // DATASET-RELATED: maximum text length\n",
    "    \"output_path\": \"models/ljspeech_models/\",      // DATASET-RELATED: output path for all training outputs.\n",
    "    \"num_loader_workers\": 4,        // number of training data loader processes. Don't set it too big. 4-8 are good values.\n",
    "    \"num_val_loader_workers\": 4,    // number of evaluation data loader processes.\n",
    "    \"phoneme_cache_path\": \"ljspeech_phonemes\",  // phoneme computation is slow, therefore, it caches results in the given folder.\n",
    "    \"use_phonemes\": true,           // use phonemes instead of raw characters. It is suggested for better pronounciation.\n",
    "    \"phoneme_language\": \"en-us\",     // depending on your target language, pick one from  https://github.com/bootphon/phonemizer#languages\n",
    "    \"text_cleaner\": \"phoneme_cleaners\"\n",
    "}\n",
    "EOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using CUDA:  True\n",
      " > Number of GPUs:  2\n",
      " > Forcing use of single GPU, id:  GeForce GTX 1080 Ti\n",
      " > Git Hash: 82c9fa5\n",
      " > Experiment folder: /vm/TTS/models/ljspeech_models/mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking-May-28-2019_11+59AM-82c9fa5\n",
      " > Setting up Audio Processor...\n",
      " | > bits:None\n",
      " | > sample_rate:22050\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:12.5\n",
      " | > frame_length_ms:50\n",
      " | > ref_level_db:20\n",
      " | > num_freq:1025\n",
      " | > power:1.5\n",
      " | > preemphasis:0.98\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0.0\n",
      " | > mel_fmax:8000.0\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > n_fft:2048\n",
      " | > hop_length:275\n",
      " | > win_length:1102\n",
      " > Using model: Tacotron2\n",
      " | > Num output units : 1025\n",
      "\n",
      " > Model has 28179554 parameters\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Data path: /vm/LJSpeech-1.1/\n",
      " | > Use phonemes: True\n",
      "   | > phoneme language: en-us\n",
      " | > Number of instances : 12000\n",
      " | > Max length sequence: 187\n",
      " | > Min length sequence: 5\n",
      " | > Avg length sequence: 98.38491666666667\n",
      " | > Num. instances discarded by max-min seq limits: 572\n",
      " | > Batch group size: 0.\n",
      "\n",
      " > Epoch 0/1000\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "   | > Step:9/357  GlobalStep:10  TotalLoss:0.74075  PostnetLoss:0.70910  DecoderLoss:0.03165  StopLoss:0.67607  GradNorm:2.04527  GradNormST:0.26345  AvgTextLen:32.5  AvgSpecLen:157.2  StepTime:1.22  LR:0.000100\n",
      "   | > Step:19/357  GlobalStep:20  TotalLoss:0.43136  PostnetLoss:0.36646  DecoderLoss:0.06490  StopLoss:0.66305  GradNorm:1.44783  GradNormST:0.51165  AvgTextLen:40.3  AvgSpecLen:210.8  StepTime:1.25  LR:0.000100\n",
      "   | > Step:29/357  GlobalStep:30  TotalLoss:0.44400  PostnetLoss:0.33824  DecoderLoss:0.10576  StopLoss:0.66726  GradNorm:0.78004  GradNormST:0.46564  AvgTextLen:49.9  AvgSpecLen:247.2  StepTime:1.39  LR:0.000100\n",
      "   | > Step:39/357  GlobalStep:40  TotalLoss:0.22867  PostnetLoss:0.13388  DecoderLoss:0.09479  StopLoss:0.56865  GradNorm:0.23699  GradNormST:1.35822  AvgTextLen:51.7  AvgSpecLen:262.8  StepTime:1.19  LR:0.000100\n",
      "   | > Step:49/357  GlobalStep:50  TotalLoss:0.41699  PostnetLoss:0.34885  DecoderLoss:0.06814  StopLoss:0.63288  GradNorm:6.25777  GradNormST:0.57494  AvgTextLen:58.2  AvgSpecLen:305.8  StepTime:1.54  LR:0.000100\n",
      "   | > Step:59/357  GlobalStep:60  TotalLoss:0.38225  PostnetLoss:0.32887  DecoderLoss:0.05338  StopLoss:0.63065  GradNorm:0.40728  GradNormST:0.43258  AvgTextLen:61.3  AvgSpecLen:319.8  StepTime:1.73  LR:0.000100\n",
      "   | > Step:69/357  GlobalStep:70  TotalLoss:0.41058  PostnetLoss:0.34171  DecoderLoss:0.06888  StopLoss:0.61289  GradNorm:0.28166  GradNormST:0.45307  AvgTextLen:66.4  AvgSpecLen:346.8  StepTime:2.04  LR:0.000100\n",
      "   | > Step:79/357  GlobalStep:80  TotalLoss:0.28934  PostnetLoss:0.21930  DecoderLoss:0.07004  StopLoss:0.37936  GradNorm:0.27134  GradNormST:0.67229  AvgTextLen:73.4  AvgSpecLen:388.5  StepTime:2.55  LR:0.000100\n",
      "   | > Step:89/357  GlobalStep:90  TotalLoss:0.52464  PostnetLoss:0.48403  DecoderLoss:0.04061  StopLoss:0.55036  GradNorm:1.17765  GradNormST:0.52229  AvgTextLen:72.2  AvgSpecLen:378.8  StepTime:2.08  LR:0.000100\n",
      "   | > Step:99/357  GlobalStep:100  TotalLoss:0.37142  PostnetLoss:0.26845  DecoderLoss:0.10297  StopLoss:0.61778  GradNorm:0.41361  GradNormST:0.33270  AvgTextLen:76.7  AvgSpecLen:395.7  StepTime:2.47  LR:0.000100\n",
      "   | > Step:109/357  GlobalStep:110  TotalLoss:0.21084  PostnetLoss:0.15310  DecoderLoss:0.05774  StopLoss:0.47790  GradNorm:1.08158  GradNormST:0.81596  AvgTextLen:79.2  AvgSpecLen:416.1  StepTime:2.17  LR:0.000100\n",
      "   | > Step:119/357  GlobalStep:120  TotalLoss:0.10134  PostnetLoss:0.07326  DecoderLoss:0.02808  StopLoss:0.37657  GradNorm:0.82405  GradNormST:0.89480  AvgTextLen:81.7  AvgSpecLen:440.0  StepTime:2.49  LR:0.000100\n",
      "   | > Step:129/357  GlobalStep:130  TotalLoss:0.15704  PostnetLoss:0.13071  DecoderLoss:0.02634  StopLoss:0.32772  GradNorm:2.05663  GradNormST:0.66076  AvgTextLen:86.7  AvgSpecLen:458.4  StepTime:3.14  LR:0.000100\n",
      "   | > Step:139/357  GlobalStep:140  TotalLoss:0.05952  PostnetLoss:0.03417  DecoderLoss:0.02535  StopLoss:0.34755  GradNorm:0.13290  GradNormST:0.72385  AvgTextLen:88.6  AvgSpecLen:461.7  StepTime:2.44  LR:0.000100\n",
      "   | > Step:149/357  GlobalStep:150  TotalLoss:0.05880  PostnetLoss:0.03438  DecoderLoss:0.02441  StopLoss:0.34780  GradNorm:0.16817  GradNormST:0.72618  AvgTextLen:89.9  AvgSpecLen:450.7  StepTime:2.53  LR:0.000100\n",
      "   | > Step:159/357  GlobalStep:160  TotalLoss:0.12693  PostnetLoss:0.10253  DecoderLoss:0.02440  StopLoss:0.28669  GradNorm:0.92278  GradNormST:0.60379  AvgTextLen:95.6  AvgSpecLen:501.9  StepTime:3.09  LR:0.000100\n",
      "   | > Step:169/357  GlobalStep:170  TotalLoss:0.08320  PostnetLoss:0.05926  DecoderLoss:0.02394  StopLoss:0.27082  GradNorm:0.50029  GradNormST:0.61070  AvgTextLen:96.6  AvgSpecLen:511.9  StepTime:3.12  LR:0.000100\n",
      "   | > Step:179/357  GlobalStep:180  TotalLoss:0.06256  PostnetLoss:0.03874  DecoderLoss:0.02382  StopLoss:0.28299  GradNorm:0.26103  GradNormST:0.68565  AvgTextLen:99.4  AvgSpecLen:538.0  StepTime:2.49  LR:0.000100\n",
      "   | > Step:189/357  GlobalStep:190  TotalLoss:0.04941  PostnetLoss:0.02667  DecoderLoss:0.02274  StopLoss:0.25502  GradNorm:0.08819  GradNormST:0.59932  AvgTextLen:100.3  AvgSpecLen:537.3  StepTime:3.05  LR:0.000100\n",
      "   | > Step:199/357  GlobalStep:200  TotalLoss:0.08815  PostnetLoss:0.06592  DecoderLoss:0.02223  StopLoss:0.23071  GradNorm:0.44316  GradNormST:0.51705  AvgTextLen:104.5  AvgSpecLen:568.5  StepTime:2.81  LR:0.000100\n",
      "   | > Step:209/357  GlobalStep:210  TotalLoss:0.04554  PostnetLoss:0.02415  DecoderLoss:0.02139  StopLoss:0.25032  GradNorm:0.09699  GradNormST:0.52839  AvgTextLen:104.1  AvgSpecLen:577.5  StepTime:2.73  LR:0.000100\n",
      "   | > Step:219/357  GlobalStep:220  TotalLoss:0.06803  PostnetLoss:0.04757  DecoderLoss:0.02045  StopLoss:0.25301  GradNorm:0.29832  GradNormST:0.58208  AvgTextLen:105.0  AvgSpecLen:563.5  StepTime:2.69  LR:0.000100\n",
      "   | > Step:229/357  GlobalStep:230  TotalLoss:0.04142  PostnetLoss:0.02186  DecoderLoss:0.01956  StopLoss:0.21152  GradNorm:0.08470  GradNormST:0.52297  AvgTextLen:110.1  AvgSpecLen:580.5  StepTime:3.24  LR:0.000100\n",
      "   | > Step:239/357  GlobalStep:240  TotalLoss:0.04640  PostnetLoss:0.02842  DecoderLoss:0.01799  StopLoss:0.19314  GradNorm:0.19704  GradNormST:0.46436  AvgTextLen:112.5  AvgSpecLen:606.8  StepTime:2.94  LR:0.000100\n",
      "   | > Step:249/357  GlobalStep:250  TotalLoss:0.04870  PostnetLoss:0.03154  DecoderLoss:0.01717  StopLoss:0.20733  GradNorm:0.20734  GradNormST:0.47283  AvgTextLen:112.0  AvgSpecLen:590.4  StepTime:2.56  LR:0.000100\n",
      "   | > Step:259/357  GlobalStep:260  TotalLoss:0.03281  PostnetLoss:0.01661  DecoderLoss:0.01619  StopLoss:0.20226  GradNorm:0.04304  GradNormST:0.43726  AvgTextLen:118.9  AvgSpecLen:643.3  StepTime:2.92  LR:0.000100\n",
      "   | > Step:269/357  GlobalStep:270  TotalLoss:0.03899  PostnetLoss:0.02337  DecoderLoss:0.01562  StopLoss:0.19835  GradNorm:0.24182  GradNormST:0.44606  AvgTextLen:119.8  AvgSpecLen:634.8  StepTime:2.99  LR:0.000100\n",
      "   | > Step:279/357  GlobalStep:280  TotalLoss:0.03128  PostnetLoss:0.01607  DecoderLoss:0.01522  StopLoss:0.18847  GradNorm:0.05960  GradNormST:0.42182  AvgTextLen:120.7  AvgSpecLen:653.2  StepTime:3.29  LR:0.000100\n",
      "   | > Step:289/357  GlobalStep:290  TotalLoss:0.03199  PostnetLoss:0.01757  DecoderLoss:0.01442  StopLoss:0.17184  GradNorm:0.09706  GradNormST:0.39664  AvgTextLen:125.1  AvgSpecLen:663.3  StepTime:3.03  LR:0.000100\n",
      "   | > Step:299/357  GlobalStep:300  TotalLoss:0.02946  PostnetLoss:0.01494  DecoderLoss:0.01453  StopLoss:0.16989  GradNorm:0.05019  GradNormST:0.38046  AvgTextLen:125.8  AvgSpecLen:664.7  StepTime:2.95  LR:0.000100\n",
      "   | > Step:309/357  GlobalStep:310  TotalLoss:0.02771  PostnetLoss:0.01403  DecoderLoss:0.01368  StopLoss:0.17305  GradNorm:0.04002  GradNormST:0.38259  AvgTextLen:127.2  AvgSpecLen:659.3  StepTime:2.89  LR:0.000100\n",
      "   | > Step:319/357  GlobalStep:320  TotalLoss:0.03165  PostnetLoss:0.01837  DecoderLoss:0.01328  StopLoss:0.16799  GradNorm:0.15949  GradNormST:0.38144  AvgTextLen:133.7  AvgSpecLen:701.9  StepTime:3.61  LR:0.000100\n",
      "   | > Step:329/357  GlobalStep:330  TotalLoss:0.03166  PostnetLoss:0.01828  DecoderLoss:0.01339  StopLoss:0.16680  GradNorm:0.17711  GradNormST:0.39492  AvgTextLen:133.8  AvgSpecLen:711.7  StepTime:3.25  LR:0.000100\n",
      "   | > Step:339/357  GlobalStep:340  TotalLoss:0.02936  PostnetLoss:0.01633  DecoderLoss:0.01303  StopLoss:0.15577  GradNorm:0.15683  GradNormST:0.37511  AvgTextLen:137.0  AvgSpecLen:719.7  StepTime:3.35  LR:0.000100\n",
      "   | > Step:349/357  GlobalStep:350  TotalLoss:0.03874  PostnetLoss:0.02577  DecoderLoss:0.01297  StopLoss:0.15026  GradNorm:0.53358  GradNormST:0.36583  AvgTextLen:140.4  AvgSpecLen:740.7  StepTime:3.03  LR:0.000100\n",
      "   | > EPOCH END -- GlobalStep:358  AvgTotalLoss:0.54296  AvgPostnetLoss:0.15370  AvgDecoderLoss:0.03548  AvgStopLoss:0.35378  EpochTime:926.92  AvgStepTime:2.59\n",
      "\n",
      " > Validation\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/vm/tf-py3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1363: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      " ! Run is removed from /vm/TTS/models/ljspeech_models/mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking-May-28-2019_11+59AM-82c9fa5\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 583, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 470, in main\n",
      "    val_loss = evaluate(model, criterion, criterion_st, ap, current_step, epoch)\n",
      "  File \"train.py\", line 297, in evaluate\n",
      "    model.forward(text_input, text_lengths, mel_input)\n",
      "  File \"/vm/TTS/models/tacotron2.py\", line 48, in forward\n",
      "    encoder_outputs, mel_specs, mask)\n",
      "  File \"/vm/tf-py3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/vm/TTS/layers/tacotron2.py\", line 231, in forward\n",
      "    mel_output, stop_token, attention_weights = self.decode(memory)\n",
      "  File \"/vm/TTS/layers/tacotron2.py\", line 196, in decode\n",
      "    self.processed_inputs, self.mask)\n",
      "  File \"/vm/tf-py3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/vm/TTS/layers/common_layers.py\", line 250, in forward\n",
      "    inputs, alignment, attention_hidden_state)\n",
      "  File \"/vm/TTS/layers/common_layers.py\", line 210, in apply_forward_attention\n",
      "    alpha[b, n + 2:] = 0\n",
      "TypeError: only integer tensors of a single element can be converted to an index\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "execution_count": 9,
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd /vm/TTS\n",
    "python train.py --config_path config.json\n",
    "#start tensorboard in another terminal\n",
    "#tensorboard --logdir=my_run:<output_path in config.json>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "python train.py --config_path config.json --restore_path /vm/TTS/models/ljspeech_models/queue-April-26-2019_03+46PM-59bbdb3\n",
    "#/path/to/your/model.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"hello TensorFlow!\")\n",
    "sess=tf.Session() \n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

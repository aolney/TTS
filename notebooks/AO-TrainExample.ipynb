{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Mozilla TTS Training Example\n",
    "\n",
    "Adapted [this gist](https://gist.github.com/erogol/97516ad65b44dbddb8cd694953187c5b) for [SoS notebook](https://vatlab.github.io/sos-docs/).\n",
    "\n",
    "Assumes you have already [cloned TTS](https://github.com/mozilla/TTS) and done `apt install espeak`\n",
    "\n",
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "exit #comment to allow execution\n",
    "wget http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
    "tar -xjf LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "exit #comment to allow execution\n",
    "shuf LJSpeech-1.1/metadata.csv > LJSpeech-1.1/metadata_shuf.csv\n",
    "head -n 12000 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_train.csv\n",
    "tail -n 1100 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_val.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Create config file for this training data\n",
    "\n",
    "Some of my local paths are hardcoded below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "#exit #comment to allow execution\n",
    "cd /vm/TTS\n",
    "cp config.json \"config.json.$(date +%Y%m%d)\"\n",
    "cat > config.json << EOM\n",
    "{\n",
    "    \"run_name\": \"mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking\",\n",
    "    \"run_description\": \"using forward attention, with original prenet, loss masking,separate stopnet, sigmoid. Compare this with 4817. Pytorch DPP\",\n",
    "\n",
    "    \"audio\":{}\n",
    "        // Audio processing parameters\n",
    "        \"num_mels\": 80,         // size of the mel spec frame. \n",
    "        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\n",
    "        \"sample_rate\": 22050,   // DATASET-RELATED: wav sample-rate. If different than the original data, it is resampled.\n",
    "        \"frame_length_ms\": 50,  // stft window length in ms.\n",
    "        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\n",
    "        \"preemphasis\": 0.98,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\n",
    "        \"min_level_db\": -100,   // normalization range\n",
    "        \"ref_level_db\": 20,     // reference level db, theoretically 20db is the sound of air.\n",
    "        \"power\": 1.5,           // value to sharpen wav signals after GL algorithm.\n",
    "        \"griffin_lim_iters\": 60,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\n",
    "        // Normalization parameters\n",
    "        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\n",
    "        \"symmetric_norm\": false, // move normalization to range [-1, 1]\n",
    "        \"max_norm\": 1,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\n",
    "        \"clip_norm\": true,      // clip normalized values into the range.\n",
    "        \"mel_fmin\": 0.0,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\n",
    "        \"mel_fmax\": 8000.0,        // maximum freq level for mel-spec. Tune for dataset!!\n",
    "        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\n",
    "    },\n",
    "\n",
    "    \"distributed\":{\n",
    "        \"backend\": \"nccl\",\n",
    "        \"url\": \"tcp:\\/\\/localhost:54321\"\n",
    "    },\n",
    "\n",
    "    \"reinit_layers\": [],\n",
    "\n",
    "    \"model\": \"Tacotron2\",          // one of the model in models/    \n",
    "    \"grad_clip\": 1,                // upper limit for gradients for clipping.\n",
    "    \"epochs\": 1000,                // total number of epochs to train.\n",
    "    \"lr\": 0.0001,                  // Initial learning rate. If Noam decay is active, maximum learning rate.\n",
    "    \"lr_decay\": false,             // if true, Noam learning rate decaying is applied through training.\n",
    "    \"warmup_steps\": 4000,          // Noam decay steps to increase the learning rate from 0 to \"lr\"\n",
    "    \"windowing\": false,            // Enables attention windowing. Used only in eval mode.\n",
    "    \"memory_size\": 5,              // ONLY TACOTRON - memory queue size used to queue network predictions to feed autoregressive connection. Useful if r < 5. \n",
    "    \"attention_norm\": \"sigmoid\",   // softmax or sigmoid. Suggested to use softmax for Tacotron2 and sigmoid for Tacotron.\n",
    "    \"prenet_type\": \"original\",     // ONLY TACOTRON2 - \"original\" or \"bn\".\n",
    "    \"prenet_dropout\": true,        // ONLY TACOTRON2 - enable/disable dropout at prenet. \n",
    "    \"use_forward_attn\": true,      // ONLY TACOTRON2 - if it uses forward attention. In general, it aligns faster.\n",
    "    \"transition_agent\": false,     // ONLY TACOTRON2 - enable/disable transition agent of forward attention.\n",
    "    \"location_attn\": false,        // ONLY TACOTRON2 - enable_disable location sensitive attention. It is enabled for TACOTRON by default.\n",
    "    \"loss_masking\": true,         // enable / disable loss masking against the sequence padding.\n",
    "    \"enable_eos_bos_chars\": false, // enable/disable beginning of sentence and end of sentence chars.\n",
    "    \"stopnet\": true,               // Train stopnet predicting the end of synthesis. \n",
    "    \"separate_stopnet\": true,     // Train stopnet seperately if 'stopnet==true'. It prevents stopnet loss to influence the rest of the model. It causes a better model, but it trains SLOWER.\n",
    "    \"tb_model_param_stats\": false,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging. \n",
    "    \n",
    "    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention.\n",
    "    \"eval_batch_size\":16,   \n",
    "    \"r\": 1,                 // Number of frames to predict for step.\n",
    "    \"wd\": 0.000001,         // Weight decay weight.\n",
    "    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\n",
    "    \"save_step\": 1000,      // Number of training steps expected to save traning stats and checkpoints.\n",
    "    \"print_step\": 10,       // Number of steps to log traning on console.\n",
    "    \"batch_group_size\": 0,  //Number of batches to shuffle after bucketing.\n",
    "\n",
    "    \"run_eval\": true,\n",
    "    \"test_delay_epochs\": 5,  //Until attention is aligned, testing only wastes computation time.\n",
    "    \"test_sentences_file\": null,  // set a file to load sentences to be used for testing. If it is null then we use default english sentences.\n",
    "    \"data_path\": \"/vm/LJSpeech-1.1/\",  // DATASET-RELATED: can overwritten from command argument\n",
    "    \"meta_file_train\": \"metadata_train.csv\",       // DATASET-RELATED: metafile for training dataloader.\n",
    "    \"meta_file_val\": \"metadata_val.csv\",    // DATASET-RELATED: metafile for evaluation dataloader.\n",
    "    \"dataset\": \"ljspeech\",       // DATASET-RELATED: one of TTS.dataset.preprocessors depending on your target dataset. Use \"tts_cache\" for pre-computed dataset by extract_features.py\n",
    "    \"min_seq_len\": 0,       // DATASET-RELATED: minimum text length to use in training\n",
    "    \"max_seq_len\": 150,     // DATASET-RELATED: maximum text length\n",
    "    \"output_path\": \"models/ljspeech_models/\",      // DATASET-RELATED: output path for all training outputs.\n",
    "    \"num_loader_workers\": 4,        // number of training data loader processes. Don't set it too big. 4-8 are good values.\n",
    "    \"num_val_loader_workers\": 4,    // number of evaluation data loader processes.\n",
    "    \"phoneme_cache_path\": \"ljspeech_phonemes\",  // phoneme computation is slow, therefore, it caches results in the given folder.\n",
    "    \"use_phonemes\": true,           // use phonemes instead of raw characters. It is suggested for better pronounciation.\n",
    "    \"phoneme_language\": \"en-us\",     // depending on your target language, pick one from  https://github.com/bootphon/phonemizer#languages\n",
    "    \"text_cleaner\": \"phoneme_cleaners\"\n",
    "}\n",
    "EOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cd /vm/TTS\n",
    "python train.py --config_path config.json\n",
    "#start tensorboard in another terminal\n",
    "#tensorboard --logdir=my_run:<output_path in config.json>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "python train.py --config_path config.json --restore_path /vm/TTS/models/ljspeech_models/queue-April-26-2019_03+46PM-59bbdb3\n",
    "#/path/to/your/model.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"hello TensorFlow!\")\n",
    "sess=tf.Session() \n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
